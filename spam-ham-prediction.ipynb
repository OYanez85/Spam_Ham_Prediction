{"cells":[{"source":"<a href=\"https://www.kaggle.com/code/oscaryezfeijo/spam-ham-prediction?scriptVersionId=178396909\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:30:18.412128Z","iopub.status.busy":"2024-05-18T14:30:18.41125Z","iopub.status.idle":"2024-05-18T14:30:18.414128Z","shell.execute_reply":"2024-05-18T14:30:18.413472Z","shell.execute_reply.started":"2024-05-18T13:39:07.184228Z"},"papermill":{"duration":0.030762,"end_time":"2024-05-18T14:30:18.414234","exception":false,"start_time":"2024-05-18T14:30:18.383472","status":"completed"},"tags":[]},"outputs":[],"source":["# Importing the libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:30:18.461078Z","iopub.status.busy":"2024-05-18T14:30:18.460498Z","iopub.status.idle":"2024-05-18T14:30:18.556966Z","shell.execute_reply":"2024-05-18T14:30:18.556332Z","shell.execute_reply.started":"2024-05-18T13:42:34.431303Z"},"papermill":{"duration":0.123732,"end_time":"2024-05-18T14:30:18.557073","exception":false,"start_time":"2024-05-18T14:30:18.433341","status":"completed"},"tags":[]},"outputs":[],"source":["# Importing the dataset\n","data =pd.read_csv('../input/spam-mails-dataset/spam_ham_dataset.csv')"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:30:18.608251Z","iopub.status.busy":"2024-05-18T14:30:18.602785Z","iopub.status.idle":"2024-05-18T14:30:18.615932Z","shell.execute_reply":"2024-05-18T14:30:18.615431Z","shell.execute_reply.started":"2024-05-18T13:42:38.181085Z"},"papermill":{"duration":0.03962,"end_time":"2024-05-18T14:30:18.616028","exception":false,"start_time":"2024-05-18T14:30:18.576408","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>label</th>\n","      <th>text</th>\n","      <th>label_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>605</td>\n","      <td>ham</td>\n","      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2349</td>\n","      <td>ham</td>\n","      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3624</td>\n","      <td>ham</td>\n","      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4685</td>\n","      <td>spam</td>\n","      <td>Subject: photoshop , windows , office . cheap ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2030</td>\n","      <td>ham</td>\n","      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0 label                                               text  \\\n","0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n","1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n","2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n","3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n","4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n","\n","   label_num  \n","0          0  \n","1          0  \n","2          0  \n","3          1  \n","4          0  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:30:18.664203Z","iopub.status.busy":"2024-05-18T14:30:18.663494Z","iopub.status.idle":"2024-05-18T14:30:18.666851Z","shell.execute_reply":"2024-05-18T14:30:18.667282Z","shell.execute_reply.started":"2024-05-18T13:42:42.324388Z"},"papermill":{"duration":0.031658,"end_time":"2024-05-18T14:30:18.667427","exception":false,"start_time":"2024-05-18T14:30:18.635769","status":"completed"},"tags":[]},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>label</th>\n","      <th>text</th>\n","      <th>label_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5166</th>\n","      <td>1518</td>\n","      <td>ham</td>\n","      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5167</th>\n","      <td>404</td>\n","      <td>ham</td>\n","      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5168</th>\n","      <td>2933</td>\n","      <td>ham</td>\n","      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5169</th>\n","      <td>1409</td>\n","      <td>ham</td>\n","      <td>Subject: industrial worksheets for august 2000...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5170</th>\n","      <td>4807</td>\n","      <td>spam</td>\n","      <td>Subject: important online banking alert\\r\\ndea...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Unnamed: 0 label                                               text  \\\n","5166        1518   ham  Subject: put the 10 on the ft\\r\\nthe transport...   \n","5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n","5168        2933   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...   \n","5169        1409   ham  Subject: industrial worksheets for august 2000...   \n","5170        4807  spam  Subject: important online banking alert\\r\\ndea...   \n","\n","      label_num  \n","5166          0  \n","5167          0  \n","5168          0  \n","5169          0  \n","5170          1  "]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data.tail()"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:30:18.720678Z","iopub.status.busy":"2024-05-18T14:30:18.719893Z","iopub.status.idle":"2024-05-18T14:30:18.723395Z","shell.execute_reply":"2024-05-18T14:30:18.722817Z","shell.execute_reply.started":"2024-05-18T13:42:48.575671Z"},"papermill":{"duration":0.035931,"end_time":"2024-05-18T14:30:18.723496","exception":false,"start_time":"2024-05-18T14:30:18.687565","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5171 entries, 0 to 5170\n","Data columns (total 4 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   Unnamed: 0  5171 non-null   int64 \n"," 1   label       5171 non-null   object\n"," 2   text        5171 non-null   object\n"," 3   label_num   5171 non-null   int64 \n","dtypes: int64(2), object(2)\n","memory usage: 161.7+ KB\n"]}],"source":["data.info()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:30:18.768244Z","iopub.status.busy":"2024-05-18T14:30:18.767459Z","iopub.status.idle":"2024-05-18T14:30:18.77022Z","shell.execute_reply":"2024-05-18T14:30:18.769636Z","shell.execute_reply.started":"2024-05-18T13:42:52.654437Z"},"papermill":{"duration":0.026675,"end_time":"2024-05-18T14:30:18.770343","exception":false,"start_time":"2024-05-18T14:30:18.743668","status":"completed"},"tags":[]},"outputs":[],"source":["# Extract texts and labels\n","texts = data['text']\n","labels = data['label_num']"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:30:18.818765Z","iopub.status.busy":"2024-05-18T14:30:18.818115Z","iopub.status.idle":"2024-05-18T14:30:25.175758Z","shell.execute_reply":"2024-05-18T14:30:25.176241Z","shell.execute_reply.started":"2024-05-18T13:44:36.732676Z"},"papermill":{"duration":6.385715,"end_time":"2024-05-18T14:30:25.176408","exception":false,"start_time":"2024-05-18T14:30:18.790693","status":"completed"},"tags":[]},"outputs":[],"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Initialize the Tokenizer and fit it on the texts\n","tokenizer = Tokenizer(num_words=5000)\n","tokenizer.fit_on_texts(texts)  # Assume 'texts' is your list of text data\n","\n","# Convert texts to sequences and pad them to ensure uniform length\n","sequences = tokenizer.texts_to_sequences(texts)\n","padded_sequences = pad_sequences(sequences, maxlen=200)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:30:25.222549Z","iopub.status.busy":"2024-05-18T14:30:25.221861Z","iopub.status.idle":"2024-05-18T14:30:25.863593Z","shell.execute_reply":"2024-05-18T14:30:25.863026Z","shell.execute_reply.started":"2024-05-18T13:47:32.652642Z"},"papermill":{"duration":0.666648,"end_time":"2024-05-18T14:30:25.863707","exception":false,"start_time":"2024-05-18T14:30:25.197059","status":"completed"},"tags":[]},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:30:25.91204Z","iopub.status.busy":"2024-05-18T14:30:25.911372Z","iopub.status.idle":"2024-05-18T14:30:28.204378Z","shell.execute_reply":"2024-05-18T14:30:28.203791Z","shell.execute_reply.started":"2024-05-18T13:47:58.532133Z"},"papermill":{"duration":2.320191,"end_time":"2024-05-18T14:30:28.204505","exception":false,"start_time":"2024-05-18T14:30:25.884314","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 200, 128)          640000    \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 128)               131584    \n","_________________________________________________________________\n","dense (Dense)                (None, 1)                 129       \n","=================================================================\n","Total params: 771,713\n","Trainable params: 771,713\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=5000, output_dim=128, input_length=200))\n","model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:30:28.251503Z","iopub.status.busy":"2024-05-18T14:30:28.250802Z","iopub.status.idle":"2024-05-18T14:33:33.797087Z","shell.execute_reply":"2024-05-18T14:33:33.797616Z","shell.execute_reply.started":"2024-05-18T13:50:03.303794Z"},"papermill":{"duration":185.572261,"end_time":"2024-05-18T14:33:33.797798","exception":false,"start_time":"2024-05-18T14:30:28.225537","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","65/65 [==============================] - 36s 551ms/step - loss: 0.3338 - accuracy: 0.8392 - val_loss: 0.1893 - val_accuracy: 0.9401\n","Epoch 2/5\n","65/65 [==============================] - 36s 560ms/step - loss: 0.0721 - accuracy: 0.9749 - val_loss: 0.0772 - val_accuracy: 0.9681\n","Epoch 3/5\n","65/65 [==============================] - 36s 551ms/step - loss: 0.0265 - accuracy: 0.9913 - val_loss: 0.0604 - val_accuracy: 0.9768\n","Epoch 4/5\n","65/65 [==============================] - 36s 549ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.0547 - val_accuracy: 0.9836\n","Epoch 5/5\n","65/65 [==============================] - 36s 553ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.0579 - val_accuracy: 0.9836\n"]}],"source":["history = model.fit(X_train, y_train, batch_size=64, epochs=5, validation_data=(X_test, y_test))\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:33:34.069236Z","iopub.status.busy":"2024-05-18T14:33:34.068613Z","iopub.status.idle":"2024-05-18T14:33:35.287159Z","shell.execute_reply":"2024-05-18T14:33:35.286604Z","shell.execute_reply.started":"2024-05-18T13:53:01.425058Z"},"papermill":{"duration":1.356193,"end_time":"2024-05-18T14:33:35.287319","exception":false,"start_time":"2024-05-18T14:33:33.931126","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["33/33 [==============================] - 1s 35ms/step - loss: 0.0579 - accuracy: 0.9836\n","Loss: 0.05793321505188942\n","Accuracy: 0.9835748672485352\n"]}],"source":["# Evaluate the model\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(f'Loss: {loss}')\n","print(f'Accuracy: {accuracy}')"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:33:35.574908Z","iopub.status.busy":"2024-05-18T14:33:35.574005Z","iopub.status.idle":"2024-05-18T14:33:35.872522Z","shell.execute_reply":"2024-05-18T14:33:35.873004Z","shell.execute_reply.started":"2024-05-18T13:53:07.942689Z"},"papermill":{"duration":0.445131,"end_time":"2024-05-18T14:33:35.873157","exception":false,"start_time":"2024-05-18T14:33:35.428026","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Spam Probability: 0.99896014\n","The email is classified as Spam\n"]}],"source":["# Assuming the previous steps and the LSTM model are already defined and trained\n","\n","# Example new email text\n","new_email = [\"Congratulations! You've won a $1000 gift card. Click here to claim now.\"]\n","\n","# Preprocess the new email text\n","new_email_seq = tokenizer.texts_to_sequences(new_email)\n","new_email_padded = pad_sequences(new_email_seq, maxlen=200)\n","\n","# Predict using the model\n","prediction = model.predict(new_email_padded)\n","print(\"Spam Probability:\", prediction[0][0])\n","\n","# Interpret the prediction\n","if prediction[0][0] >= 0.5:\n","    print(\"The email is classified as Spam\")\n","else:\n","    print(\"The email is classified as Ham\")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:33:36.16101Z","iopub.status.busy":"2024-05-18T14:33:36.160375Z","iopub.status.idle":"2024-05-18T14:33:36.232255Z","shell.execute_reply":"2024-05-18T14:33:36.231747Z","shell.execute_reply.started":"2024-05-18T13:55:39.965745Z"},"papermill":{"duration":0.219181,"end_time":"2024-05-18T14:33:36.232403","exception":false,"start_time":"2024-05-18T14:33:36.013222","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Spam Probability: 0.08969656\n","The email is classified as Ham\n"]}],"source":["# Assuming the previous steps and the LSTM model are already defined and trained\n","\n","# Example new email text\n","new_email = [\" Hi John, just a reminder about our meeting that is scheduled for 3 PM. Please let us know if you need to reschedule, regards Jane.\"]\n","\n","# Preprocess the new email text\n","new_email_seq = tokenizer.texts_to_sequences(new_email)\n","new_email_padded = pad_sequences(new_email_seq, maxlen=200)\n","\n","# Predict using the model\n","prediction = model.predict(new_email_padded)\n","print(\"Spam Probability:\", prediction[0][0])\n","\n","# Interpret the prediction\n","if prediction[0][0] >= 0.5:\n","    print(\"The email is classified as Spam\")\n","else:\n","    print(\"The email is classified as Ham\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:33:36.520823Z","iopub.status.busy":"2024-05-18T14:33:36.520084Z","iopub.status.idle":"2024-05-18T14:33:36.522814Z","shell.execute_reply":"2024-05-18T14:33:36.523253Z","shell.execute_reply.started":"2024-05-18T13:58:30.570073Z"},"papermill":{"duration":0.150808,"end_time":"2024-05-18T14:33:36.523397","exception":false,"start_time":"2024-05-18T14:33:36.372589","status":"completed"},"tags":[]},"outputs":[],"source":["import numpy as np\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Define the discriminator\n","def create_discriminator(max_sequence_length, vocab_size):\n","    discriminator_input = Input(shape=(max_sequence_length,))\n","    \n","    # Define the discriminator architecture (e.g., LSTM-based)\n","    x = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(discriminator_input)\n","    x = LSTM(units=64)(x)  # LSTM layer with 64 units (adjust as needed)\n","    \n","    # Output layer for classifying as spam (1) or ham (0)\n","    spam_classifier_output = Dense(1, activation='sigmoid')(x)\n","    \n","    discriminator_model = Model(discriminator_input, spam_classifier_output)\n","    return discriminator_model\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:33:36.810123Z","iopub.status.busy":"2024-05-18T14:33:36.809162Z","iopub.status.idle":"2024-05-18T14:33:37.046624Z","shell.execute_reply":"2024-05-18T14:33:37.04715Z","shell.execute_reply.started":"2024-05-18T14:01:42.598673Z"},"papermill":{"duration":0.383812,"end_time":"2024-05-18T14:33:37.047286","exception":false,"start_time":"2024-05-18T14:33:36.663474","status":"completed"},"tags":[]},"outputs":[],"source":["# Define the discriminator components\n","max_sequence_length = 100  # Adjust as needed\n","vocab_size = 10000  # Adjust as needed\n","embedding_dim = 100  # Adjust as needed\n","\n","# Create the discriminator\n","discriminator = create_discriminator(max_sequence_length, vocab_size)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:33:37.338393Z","iopub.status.busy":"2024-05-18T14:33:37.33775Z","iopub.status.idle":"2024-05-18T14:33:37.343557Z","shell.execute_reply":"2024-05-18T14:33:37.342961Z","shell.execute_reply.started":"2024-05-18T14:01:45.223559Z"},"papermill":{"duration":0.156471,"end_time":"2024-05-18T14:33:37.343657","exception":false,"start_time":"2024-05-18T14:33:37.187186","status":"completed"},"tags":[]},"outputs":[],"source":["# Compile the discriminator for binary classification\n","optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n","discriminator.compile(loss='binary_crossentropy',\n","                      optimizer=optimizer,\n","                      metrics=['accuracy'])"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:33:37.630012Z","iopub.status.busy":"2024-05-18T14:33:37.628815Z","iopub.status.idle":"2024-05-18T14:33:37.682984Z","shell.execute_reply":"2024-05-18T14:33:37.682362Z","shell.execute_reply.started":"2024-05-18T14:03:13.746762Z"},"papermill":{"duration":0.199933,"end_time":"2024-05-18T14:33:37.68309","exception":false,"start_time":"2024-05-18T14:33:37.483157","status":"completed"},"tags":[]},"outputs":[],"source":["# Load labeled dataset\n","import pandas as pd\n","your_dataset = pd.read_csv('../input/spam-mails-dataset/spam_ham_dataset.csv')\n","\n","# Assuming your dataset has a 'text' column for email text and a 'label' column for spam/ham labels\n","email_text = your_dataset['text'].tolist()\n","labels = your_dataset['label'].tolist()"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:33:38.019805Z","iopub.status.busy":"2024-05-18T14:33:37.983572Z","iopub.status.idle":"2024-05-18T14:33:39.688428Z","shell.execute_reply":"2024-05-18T14:33:39.687724Z","shell.execute_reply.started":"2024-05-18T14:08:33.542882Z"},"papermill":{"duration":1.864862,"end_time":"2024-05-18T14:33:39.68855","exception":false,"start_time":"2024-05-18T14:33:37.823688","status":"completed"},"tags":[]},"outputs":[],"source":["# Create a tokenizer and fit it on the email text\n","tokenizer = Tokenizer(num_words=vocab_size)\n","tokenizer.fit_on_texts(email_text)\n","\n","# Convert text to numerical sequences\n","sequences = tokenizer.texts_to_sequences(email_text)\n","\n","# Pad sequences to ensure the same length\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n","\n","# Convert labels to NumPy array\n","labels = np.array(labels)\n","\n","# Shuffle the data and labels\n","shuffle_indices = np.random.permutation(len(padded_sequences))\n","padded_sequences = padded_sequences[shuffle_indices]\n","labels = labels[shuffle_indices]"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:33:40.018003Z","iopub.status.busy":"2024-05-18T14:33:40.007715Z","iopub.status.idle":"2024-05-18T14:33:41.537086Z","shell.execute_reply":"2024-05-18T14:33:41.536421Z","shell.execute_reply.started":"2024-05-18T14:09:20.302353Z"},"papermill":{"duration":1.708406,"end_time":"2024-05-18T14:33:41.537195","exception":false,"start_time":"2024-05-18T14:33:39.828789","status":"completed"},"tags":[]},"outputs":[],"source":["# Convert labels to numerical values (0 for ham, 1 for spam)\n","labels = [1 if label == 'spam' else 0 for label in labels]\n","\n","# Create a tokenizer and fit it on the email text\n","tokenizer = Tokenizer(num_words=vocab_size)\n","tokenizer.fit_on_texts(email_text)\n","\n","# Convert text to numerical sequences\n","sequences = tokenizer.texts_to_sequences(email_text)\n","\n","# Pad sequences to ensure the same length\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n","\n","# Convert labels to NumPy array\n","labels = np.array(labels)\n","\n","# Shuffle the data and labels\n","shuffle_indices = np.random.permutation(len(padded_sequences))\n","padded_sequences = padded_sequences[shuffle_indices]\n","labels = labels[shuffle_indices]"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:33:41.827477Z","iopub.status.busy":"2024-05-18T14:33:41.826785Z","iopub.status.idle":"2024-05-18T14:34:08.007886Z","shell.execute_reply":"2024-05-18T14:34:08.00728Z","shell.execute_reply.started":"2024-05-18T14:11:23.950895Z"},"papermill":{"duration":26.329356,"end_time":"2024-05-18T14:34:08.007998","exception":false,"start_time":"2024-05-18T14:33:41.678642","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Batch 1/161, Loss: 0.6937505006790161, Accuracy: 0.4375\n","Epoch 1, Batch 2/161, Loss: 0.6922463774681091, Accuracy: 0.59375\n","Epoch 1, Batch 3/161, Loss: 0.6936545968055725, Accuracy: 0.5\n","Epoch 1, Batch 4/161, Loss: 0.693144679069519, Accuracy: 0.5625\n","Epoch 1, Batch 5/161, Loss: 0.6915252804756165, Accuracy: 0.65625\n","Epoch 1, Batch 6/161, Loss: 0.6932979822158813, Accuracy: 0.53125\n","Epoch 1, Batch 7/161, Loss: 0.6906138062477112, Accuracy: 0.71875\n","Epoch 1, Batch 8/161, Loss: 0.6920738220214844, Accuracy: 0.625\n","Epoch 1, Batch 9/161, Loss: 0.6902031302452087, Accuracy: 0.65625\n","Epoch 1, Batch 10/161, Loss: 0.6911007165908813, Accuracy: 0.59375\n","Epoch 1, Batch 11/161, Loss: 0.6853820085525513, Accuracy: 0.78125\n","Epoch 1, Batch 12/161, Loss: 0.6911554336547852, Accuracy: 0.625\n","Epoch 1, Batch 13/161, Loss: 0.687399685382843, Accuracy: 0.6875\n","Epoch 1, Batch 14/161, Loss: 0.6902885437011719, Accuracy: 0.625\n","Epoch 1, Batch 15/161, Loss: 0.6858815550804138, Accuracy: 0.65625\n","Epoch 1, Batch 16/161, Loss: 0.6867445707321167, Accuracy: 0.625\n","Epoch 1, Batch 17/161, Loss: 0.6826843023300171, Accuracy: 0.71875\n","Epoch 1, Batch 18/161, Loss: 0.6807813048362732, Accuracy: 0.75\n","Epoch 1, Batch 19/161, Loss: 0.6835261583328247, Accuracy: 0.65625\n","Epoch 1, Batch 20/161, Loss: 0.6847528219223022, Accuracy: 0.6875\n","Epoch 1, Batch 21/161, Loss: 0.6827871203422546, Accuracy: 0.65625\n","Epoch 1, Batch 22/161, Loss: 0.6779124140739441, Accuracy: 0.71875\n","Epoch 1, Batch 23/161, Loss: 0.6803779602050781, Accuracy: 0.65625\n","Epoch 1, Batch 24/161, Loss: 0.671913206577301, Accuracy: 0.78125\n","Epoch 1, Batch 25/161, Loss: 0.6754810810089111, Accuracy: 0.71875\n","Epoch 1, Batch 26/161, Loss: 0.6729773283004761, Accuracy: 0.71875\n","Epoch 1, Batch 27/161, Loss: 0.6553744077682495, Accuracy: 0.84375\n","Epoch 1, Batch 28/161, Loss: 0.7007468938827515, Accuracy: 0.46875\n","Epoch 1, Batch 29/161, Loss: 0.666736364364624, Accuracy: 0.71875\n","Epoch 1, Batch 30/161, Loss: 0.6805145144462585, Accuracy: 0.625\n","Epoch 1, Batch 31/161, Loss: 0.6791247129440308, Accuracy: 0.625\n","Epoch 1, Batch 32/161, Loss: 0.6719759702682495, Accuracy: 0.65625\n","Epoch 1, Batch 33/161, Loss: 0.6412997245788574, Accuracy: 0.8125\n","Epoch 1, Batch 34/161, Loss: 0.6635727286338806, Accuracy: 0.6875\n","Epoch 1, Batch 35/161, Loss: 0.6646029949188232, Accuracy: 0.65625\n","Epoch 1, Batch 36/161, Loss: 0.5947349071502686, Accuracy: 0.90625\n","Epoch 1, Batch 37/161, Loss: 0.6097288131713867, Accuracy: 0.78125\n","Epoch 1, Batch 38/161, Loss: 0.636954128742218, Accuracy: 0.6875\n","Epoch 1, Batch 39/161, Loss: 0.5804583430290222, Accuracy: 0.78125\n","Epoch 1, Batch 40/161, Loss: 0.624976634979248, Accuracy: 0.6875\n","Epoch 1, Batch 41/161, Loss: 0.7283952236175537, Accuracy: 0.5625\n","Epoch 1, Batch 42/161, Loss: 0.5746147036552429, Accuracy: 0.75\n","Epoch 1, Batch 43/161, Loss: 0.5852518677711487, Accuracy: 0.75\n","Epoch 1, Batch 44/161, Loss: 0.6019995808601379, Accuracy: 0.71875\n","Epoch 1, Batch 45/161, Loss: 0.6144328713417053, Accuracy: 0.6875\n","Epoch 1, Batch 46/161, Loss: 0.7000752687454224, Accuracy: 0.625\n","Epoch 1, Batch 47/161, Loss: 0.6942356824874878, Accuracy: 0.59375\n","Epoch 1, Batch 48/161, Loss: 0.6114952564239502, Accuracy: 0.71875\n","Epoch 1, Batch 49/161, Loss: 0.7166717052459717, Accuracy: 0.53125\n","Epoch 1, Batch 50/161, Loss: 0.6543788313865662, Accuracy: 0.65625\n","Epoch 1, Batch 51/161, Loss: 0.6064850091934204, Accuracy: 0.71875\n","Epoch 1, Batch 52/161, Loss: 0.5887631773948669, Accuracy: 0.75\n","Epoch 1, Batch 53/161, Loss: 0.6281476020812988, Accuracy: 0.6875\n","Epoch 1, Batch 54/161, Loss: 0.6772879362106323, Accuracy: 0.59375\n","Epoch 1, Batch 55/161, Loss: 0.6001155376434326, Accuracy: 0.71875\n","Epoch 1, Batch 56/161, Loss: 0.5862666368484497, Accuracy: 0.75\n","Epoch 1, Batch 57/161, Loss: 0.6139590740203857, Accuracy: 0.6875\n","Epoch 1, Batch 58/161, Loss: 0.5742855072021484, Accuracy: 0.75\n","Epoch 1, Batch 59/161, Loss: 0.5514096021652222, Accuracy: 0.78125\n","Epoch 1, Batch 60/161, Loss: 0.6627026796340942, Accuracy: 0.65625\n","Epoch 1, Batch 61/161, Loss: 0.5863743424415588, Accuracy: 0.71875\n","Epoch 1, Batch 62/161, Loss: 0.5959122180938721, Accuracy: 0.71875\n","Epoch 1, Batch 63/161, Loss: 0.6411157250404358, Accuracy: 0.65625\n","Epoch 1, Batch 64/161, Loss: 0.531593382358551, Accuracy: 0.78125\n","Epoch 1, Batch 65/161, Loss: 0.5400552749633789, Accuracy: 0.78125\n","Epoch 1, Batch 66/161, Loss: 0.5825893878936768, Accuracy: 0.71875\n","Epoch 1, Batch 67/161, Loss: 0.6424878239631653, Accuracy: 0.65625\n","Epoch 1, Batch 68/161, Loss: 0.552517831325531, Accuracy: 0.75\n","Epoch 1, Batch 69/161, Loss: 0.5303840637207031, Accuracy: 0.78125\n","Epoch 1, Batch 70/161, Loss: 0.5942491888999939, Accuracy: 0.71875\n","Epoch 1, Batch 71/161, Loss: 0.5898283123970032, Accuracy: 0.71875\n","Epoch 1, Batch 72/161, Loss: 0.6305729746818542, Accuracy: 0.6875\n","Epoch 1, Batch 73/161, Loss: 0.5638480186462402, Accuracy: 0.75\n","Epoch 1, Batch 74/161, Loss: 0.5765403509140015, Accuracy: 0.75\n","Epoch 1, Batch 75/161, Loss: 0.5818073153495789, Accuracy: 0.71875\n","Epoch 1, Batch 76/161, Loss: 0.5890188217163086, Accuracy: 0.71875\n","Epoch 1, Batch 77/161, Loss: 0.5851863622665405, Accuracy: 0.71875\n","Epoch 1, Batch 78/161, Loss: 0.6284850239753723, Accuracy: 0.6875\n","Epoch 1, Batch 79/161, Loss: 0.5122450590133667, Accuracy: 0.8125\n","Epoch 1, Batch 80/161, Loss: 0.5270205736160278, Accuracy: 0.78125\n","Epoch 1, Batch 81/161, Loss: 0.5123425722122192, Accuracy: 0.8125\n","Epoch 1, Batch 82/161, Loss: 0.6162275671958923, Accuracy: 0.71875\n","Epoch 1, Batch 83/161, Loss: 0.6000187397003174, Accuracy: 0.71875\n","Epoch 1, Batch 84/161, Loss: 0.6024824380874634, Accuracy: 0.71875\n","Epoch 1, Batch 85/161, Loss: 0.6005626916885376, Accuracy: 0.71875\n","Epoch 1, Batch 86/161, Loss: 0.6132391095161438, Accuracy: 0.71875\n","Epoch 1, Batch 87/161, Loss: 0.5630692839622498, Accuracy: 0.75\n","Epoch 1, Batch 88/161, Loss: 0.5819363594055176, Accuracy: 0.71875\n","Epoch 1, Batch 89/161, Loss: 0.643332839012146, Accuracy: 0.65625\n","Epoch 1, Batch 90/161, Loss: 0.5669724345207214, Accuracy: 0.75\n","Epoch 1, Batch 91/161, Loss: 0.6493736505508423, Accuracy: 0.65625\n","Epoch 1, Batch 92/161, Loss: 0.6662384271621704, Accuracy: 0.625\n","Epoch 1, Batch 93/161, Loss: 0.5421118140220642, Accuracy: 0.78125\n","Epoch 1, Batch 94/161, Loss: 0.6320251822471619, Accuracy: 0.65625\n","Epoch 1, Batch 95/161, Loss: 0.5766209363937378, Accuracy: 0.75\n","Epoch 1, Batch 96/161, Loss: 0.5348687767982483, Accuracy: 0.78125\n","Epoch 1, Batch 97/161, Loss: 0.532595157623291, Accuracy: 0.78125\n","Epoch 1, Batch 98/161, Loss: 0.7309156656265259, Accuracy: 0.59375\n","Epoch 1, Batch 99/161, Loss: 0.5561587810516357, Accuracy: 0.75\n","Epoch 1, Batch 100/161, Loss: 0.6165847778320312, Accuracy: 0.6875\n","Epoch 1, Batch 101/161, Loss: 0.5272151231765747, Accuracy: 0.8125\n","Epoch 1, Batch 102/161, Loss: 0.7509739995002747, Accuracy: 0.5625\n","Epoch 1, Batch 103/161, Loss: 0.5971366167068481, Accuracy: 0.71875\n","Epoch 1, Batch 104/161, Loss: 0.5985239744186401, Accuracy: 0.71875\n","Epoch 1, Batch 105/161, Loss: 0.5771550536155701, Accuracy: 0.75\n","Epoch 1, Batch 106/161, Loss: 0.6481450796127319, Accuracy: 0.65625\n","Epoch 1, Batch 107/161, Loss: 0.6017208695411682, Accuracy: 0.71875\n","Epoch 1, Batch 108/161, Loss: 0.5755439400672913, Accuracy: 0.75\n","Epoch 1, Batch 109/161, Loss: 0.6715139150619507, Accuracy: 0.625\n","Epoch 1, Batch 110/161, Loss: 0.6009185910224915, Accuracy: 0.71875\n","Epoch 1, Batch 111/161, Loss: 0.4939610958099365, Accuracy: 0.84375\n","Epoch 1, Batch 112/161, Loss: 0.5409541130065918, Accuracy: 0.78125\n","Epoch 1, Batch 113/161, Loss: 0.4603845477104187, Accuracy: 0.84375\n","Epoch 1, Batch 114/161, Loss: 0.7141909599304199, Accuracy: 0.625\n","Epoch 1, Batch 115/161, Loss: 0.7092275619506836, Accuracy: 0.625\n","Epoch 1, Batch 116/161, Loss: 0.6321059465408325, Accuracy: 0.6875\n","Epoch 1, Batch 117/161, Loss: 0.5199288129806519, Accuracy: 0.8125\n","Epoch 1, Batch 118/161, Loss: 0.6529924869537354, Accuracy: 0.65625\n","Epoch 1, Batch 119/161, Loss: 0.575058102607727, Accuracy: 0.75\n","Epoch 1, Batch 120/161, Loss: 0.7007530331611633, Accuracy: 0.59375\n","Epoch 1, Batch 121/161, Loss: 0.5147053003311157, Accuracy: 0.8125\n","Epoch 1, Batch 122/161, Loss: 0.6150223016738892, Accuracy: 0.6875\n","Epoch 1, Batch 123/161, Loss: 0.5296392440795898, Accuracy: 0.78125\n","Epoch 1, Batch 124/161, Loss: 0.5685316324234009, Accuracy: 0.75\n","Epoch 1, Batch 125/161, Loss: 0.7262043356895447, Accuracy: 0.59375\n","Epoch 1, Batch 126/161, Loss: 0.6574512720108032, Accuracy: 0.65625\n","Epoch 1, Batch 127/161, Loss: 0.5477915406227112, Accuracy: 0.78125\n","Epoch 1, Batch 128/161, Loss: 0.6991131901741028, Accuracy: 0.59375\n","Epoch 1, Batch 129/161, Loss: 0.5541765689849854, Accuracy: 0.78125\n","Epoch 1, Batch 130/161, Loss: 0.6209124326705933, Accuracy: 0.6875\n","Epoch 1, Batch 131/161, Loss: 0.5206195116043091, Accuracy: 0.8125\n","Epoch 1, Batch 132/161, Loss: 0.6569821238517761, Accuracy: 0.65625\n","Epoch 1, Batch 133/161, Loss: 0.6216818690299988, Accuracy: 0.6875\n","Epoch 1, Batch 134/161, Loss: 0.5941647291183472, Accuracy: 0.71875\n","Epoch 1, Batch 135/161, Loss: 0.5380339622497559, Accuracy: 0.78125\n","Epoch 1, Batch 136/161, Loss: 0.5004574060440063, Accuracy: 0.8125\n","Epoch 1, Batch 137/161, Loss: 0.6854287385940552, Accuracy: 0.625\n","Epoch 1, Batch 138/161, Loss: 0.5345375537872314, Accuracy: 0.78125\n","Epoch 1, Batch 139/161, Loss: 0.5632307529449463, Accuracy: 0.75\n","Epoch 1, Batch 140/161, Loss: 0.6862030029296875, Accuracy: 0.625\n","Epoch 1, Batch 141/161, Loss: 0.6325405836105347, Accuracy: 0.6875\n","Epoch 1, Batch 142/161, Loss: 0.5675653219223022, Accuracy: 0.75\n","Epoch 1, Batch 143/161, Loss: 0.6034446358680725, Accuracy: 0.6875\n","Epoch 1, Batch 144/161, Loss: 0.649189829826355, Accuracy: 0.65625\n","Epoch 1, Batch 145/161, Loss: 0.5413638353347778, Accuracy: 0.78125\n","Epoch 1, Batch 146/161, Loss: 0.5413356423377991, Accuracy: 0.78125\n","Epoch 1, Batch 147/161, Loss: 0.6634579300880432, Accuracy: 0.65625\n","Epoch 1, Batch 148/161, Loss: 0.6554467678070068, Accuracy: 0.65625\n","Epoch 1, Batch 149/161, Loss: 0.5697269439697266, Accuracy: 0.75\n","Epoch 1, Batch 150/161, Loss: 0.713138997554779, Accuracy: 0.59375\n","Epoch 1, Batch 151/161, Loss: 0.6434282064437866, Accuracy: 0.65625\n","Epoch 1, Batch 152/161, Loss: 0.5023342370986938, Accuracy: 0.84375\n","Epoch 1, Batch 153/161, Loss: 0.6286659836769104, Accuracy: 0.6875\n","Epoch 1, Batch 154/161, Loss: 0.6073545217514038, Accuracy: 0.71875\n","Epoch 1, Batch 155/161, Loss: 0.6266610622406006, Accuracy: 0.6875\n","Epoch 1, Batch 156/161, Loss: 0.5682443380355835, Accuracy: 0.75\n","Epoch 1, Batch 157/161, Loss: 0.543112576007843, Accuracy: 0.78125\n","Epoch 1, Batch 158/161, Loss: 0.48159921169281006, Accuracy: 0.84375\n","Epoch 1, Batch 159/161, Loss: 0.5866878628730774, Accuracy: 0.71875\n","Epoch 1, Batch 160/161, Loss: 0.5531824231147766, Accuracy: 0.75\n","Epoch 1, Batch 161/161, Loss: 0.5294359922409058, Accuracy: 0.78125\n","Epoch 2, Batch 1/161, Loss: 0.5577154159545898, Accuracy: 0.75\n","Epoch 2, Batch 2/161, Loss: 0.744732677936554, Accuracy: 0.59375\n","Epoch 2, Batch 3/161, Loss: 0.6583313345909119, Accuracy: 0.65625\n","Epoch 2, Batch 4/161, Loss: 0.6445834636688232, Accuracy: 0.65625\n","Epoch 2, Batch 5/161, Loss: 0.5677257776260376, Accuracy: 0.75\n","Epoch 2, Batch 6/161, Loss: 0.6440393924713135, Accuracy: 0.65625\n","Epoch 2, Batch 7/161, Loss: 0.5802537798881531, Accuracy: 0.75\n","Epoch 2, Batch 8/161, Loss: 0.6393671035766602, Accuracy: 0.65625\n","Epoch 2, Batch 9/161, Loss: 0.6410279273986816, Accuracy: 0.65625\n","Epoch 2, Batch 10/161, Loss: 0.696791410446167, Accuracy: 0.59375\n","Epoch 2, Batch 11/161, Loss: 0.5290441513061523, Accuracy: 0.8125\n","Epoch 2, Batch 12/161, Loss: 0.6590415239334106, Accuracy: 0.625\n","Epoch 2, Batch 13/161, Loss: 0.6172497272491455, Accuracy: 0.6875\n","Epoch 2, Batch 14/161, Loss: 0.666881263256073, Accuracy: 0.625\n","Epoch 2, Batch 15/161, Loss: 0.6359044313430786, Accuracy: 0.65625\n","Epoch 2, Batch 16/161, Loss: 0.664840042591095, Accuracy: 0.625\n","Epoch 2, Batch 17/161, Loss: 0.5951350927352905, Accuracy: 0.71875\n","Epoch 2, Batch 18/161, Loss: 0.5792702436447144, Accuracy: 0.75\n","Epoch 2, Batch 19/161, Loss: 0.6388139128684998, Accuracy: 0.65625\n","Epoch 2, Batch 20/161, Loss: 0.6213440895080566, Accuracy: 0.6875\n","Epoch 2, Batch 21/161, Loss: 0.6409059762954712, Accuracy: 0.65625\n","Epoch 2, Batch 22/161, Loss: 0.5911966562271118, Accuracy: 0.71875\n","Epoch 2, Batch 23/161, Loss: 0.6280924081802368, Accuracy: 0.65625\n","Epoch 2, Batch 24/161, Loss: 0.543859601020813, Accuracy: 0.78125\n","Epoch 2, Batch 25/161, Loss: 0.5976483821868896, Accuracy: 0.71875\n","Epoch 2, Batch 26/161, Loss: 0.596929669380188, Accuracy: 0.71875\n","Epoch 2, Batch 27/161, Loss: 0.4885496497154236, Accuracy: 0.84375\n","Epoch 2, Batch 28/161, Loss: 0.8237079977989197, Accuracy: 0.46875\n","Epoch 2, Batch 29/161, Loss: 0.5895516872406006, Accuracy: 0.71875\n","Epoch 2, Batch 30/161, Loss: 0.6622437238693237, Accuracy: 0.625\n","Epoch 2, Batch 31/161, Loss: 0.662531852722168, Accuracy: 0.625\n","Epoch 2, Batch 32/161, Loss: 0.6364856958389282, Accuracy: 0.65625\n","Epoch 2, Batch 33/161, Loss: 0.5286752581596375, Accuracy: 0.8125\n","Epoch 2, Batch 34/161, Loss: 0.6171537637710571, Accuracy: 0.6875\n","Epoch 2, Batch 35/161, Loss: 0.6385856866836548, Accuracy: 0.65625\n","Epoch 2, Batch 36/161, Loss: 0.45026519894599915, Accuracy: 0.90625\n","Epoch 2, Batch 37/161, Loss: 0.5370289087295532, Accuracy: 0.78125\n","Epoch 2, Batch 38/161, Loss: 0.6146983504295349, Accuracy: 0.6875\n","Epoch 2, Batch 39/161, Loss: 0.5203419923782349, Accuracy: 0.78125\n","Epoch 2, Batch 40/161, Loss: 0.6116290092468262, Accuracy: 0.6875\n","Epoch 2, Batch 41/161, Loss: 0.7537037134170532, Accuracy: 0.5625\n","Epoch 2, Batch 42/161, Loss: 0.5505843758583069, Accuracy: 0.75\n","Epoch 2, Batch 43/161, Loss: 0.5619730949401855, Accuracy: 0.75\n","Epoch 2, Batch 44/161, Loss: 0.5936143398284912, Accuracy: 0.71875\n","Epoch 2, Batch 45/161, Loss: 0.6168631315231323, Accuracy: 0.6875\n","Epoch 2, Batch 46/161, Loss: 0.6613397002220154, Accuracy: 0.625\n","Epoch 2, Batch 47/161, Loss: 0.689056396484375, Accuracy: 0.59375\n","Epoch 2, Batch 48/161, Loss: 0.5895688533782959, Accuracy: 0.71875\n","Epoch 2, Batch 49/161, Loss: 0.7224887609481812, Accuracy: 0.53125\n","Epoch 2, Batch 50/161, Loss: 0.6333080530166626, Accuracy: 0.65625\n","Epoch 2, Batch 51/161, Loss: 0.59638911485672, Accuracy: 0.71875\n","Epoch 2, Batch 52/161, Loss: 0.5714167952537537, Accuracy: 0.75\n","Epoch 2, Batch 53/161, Loss: 0.611160159111023, Accuracy: 0.6875\n","Epoch 2, Batch 54/161, Loss: 0.6780754923820496, Accuracy: 0.59375\n","Epoch 2, Batch 55/161, Loss: 0.5921259522438049, Accuracy: 0.71875\n","Epoch 2, Batch 56/161, Loss: 0.5673910975456238, Accuracy: 0.75\n","Epoch 2, Batch 57/161, Loss: 0.6061210036277771, Accuracy: 0.6875\n","Epoch 2, Batch 58/161, Loss: 0.56358802318573, Accuracy: 0.75\n","Epoch 2, Batch 59/161, Loss: 0.5362300276756287, Accuracy: 0.78125\n","Epoch 2, Batch 60/161, Loss: 0.6404434442520142, Accuracy: 0.65625\n","Epoch 2, Batch 61/161, Loss: 0.6030232310295105, Accuracy: 0.71875\n","Epoch 2, Batch 62/161, Loss: 0.5815705060958862, Accuracy: 0.71875\n","Epoch 2, Batch 63/161, Loss: 0.6333489418029785, Accuracy: 0.65625\n","Epoch 2, Batch 64/161, Loss: 0.527150571346283, Accuracy: 0.78125\n","Epoch 2, Batch 65/161, Loss: 0.5293954610824585, Accuracy: 0.78125\n","Epoch 2, Batch 66/161, Loss: 0.5809771418571472, Accuracy: 0.71875\n","Epoch 2, Batch 67/161, Loss: 0.6349584460258484, Accuracy: 0.65625\n","Epoch 2, Batch 68/161, Loss: 0.5398645997047424, Accuracy: 0.75\n","Epoch 2, Batch 69/161, Loss: 0.5277994275093079, Accuracy: 0.78125\n","Epoch 2, Batch 70/161, Loss: 0.5881668329238892, Accuracy: 0.71875\n","Epoch 2, Batch 71/161, Loss: 0.5775355100631714, Accuracy: 0.71875\n","Epoch 2, Batch 72/161, Loss: 0.619188666343689, Accuracy: 0.6875\n","Epoch 2, Batch 73/161, Loss: 0.5508670806884766, Accuracy: 0.75\n","Epoch 2, Batch 74/161, Loss: 0.5577361583709717, Accuracy: 0.75\n","Epoch 2, Batch 75/161, Loss: 0.572982668876648, Accuracy: 0.71875\n","Epoch 2, Batch 76/161, Loss: 0.5739190578460693, Accuracy: 0.71875\n","Epoch 2, Batch 77/161, Loss: 0.573930025100708, Accuracy: 0.71875\n","Epoch 2, Batch 78/161, Loss: 0.6188646554946899, Accuracy: 0.6875\n","Epoch 2, Batch 79/161, Loss: 0.4894086420536041, Accuracy: 0.8125\n","Epoch 2, Batch 80/161, Loss: 0.5225065350532532, Accuracy: 0.78125\n","Epoch 2, Batch 81/161, Loss: 0.4971373677253723, Accuracy: 0.8125\n","Epoch 2, Batch 82/161, Loss: 0.5923449993133545, Accuracy: 0.71875\n","Epoch 2, Batch 83/161, Loss: 0.5816251635551453, Accuracy: 0.71875\n","Epoch 2, Batch 84/161, Loss: 0.5863231420516968, Accuracy: 0.71875\n","Epoch 2, Batch 85/161, Loss: 0.5969839692115784, Accuracy: 0.71875\n","Epoch 2, Batch 86/161, Loss: 0.5911445021629333, Accuracy: 0.71875\n","Epoch 2, Batch 87/161, Loss: 0.5513776540756226, Accuracy: 0.75\n","Epoch 2, Batch 88/161, Loss: 0.5758850574493408, Accuracy: 0.71875\n","Epoch 2, Batch 89/161, Loss: 0.6254482865333557, Accuracy: 0.65625\n","Epoch 2, Batch 90/161, Loss: 0.5615981817245483, Accuracy: 0.75\n","Epoch 2, Batch 91/161, Loss: 0.6303941011428833, Accuracy: 0.65625\n","Epoch 2, Batch 92/161, Loss: 0.6712849140167236, Accuracy: 0.625\n","Epoch 2, Batch 93/161, Loss: 0.5251060724258423, Accuracy: 0.78125\n","Epoch 2, Batch 94/161, Loss: 0.6259142160415649, Accuracy: 0.65625\n","Epoch 2, Batch 95/161, Loss: 0.5570703744888306, Accuracy: 0.75\n","Epoch 2, Batch 96/161, Loss: 0.5202893018722534, Accuracy: 0.78125\n","Epoch 2, Batch 97/161, Loss: 0.5283681750297546, Accuracy: 0.78125\n","Epoch 2, Batch 98/161, Loss: 0.7038650512695312, Accuracy: 0.59375\n","Epoch 2, Batch 99/161, Loss: 0.5543297529220581, Accuracy: 0.75\n","Epoch 2, Batch 100/161, Loss: 0.6040332317352295, Accuracy: 0.6875\n","Epoch 2, Batch 101/161, Loss: 0.5133426785469055, Accuracy: 0.8125\n","Epoch 2, Batch 102/161, Loss: 0.7425603270530701, Accuracy: 0.5625\n","Epoch 2, Batch 103/161, Loss: 0.5889208316802979, Accuracy: 0.71875\n","Epoch 2, Batch 104/161, Loss: 0.5835379958152771, Accuracy: 0.71875\n","Epoch 2, Batch 105/161, Loss: 0.5630086660385132, Accuracy: 0.75\n","Epoch 2, Batch 106/161, Loss: 0.640265703201294, Accuracy: 0.65625\n","Epoch 2, Batch 107/161, Loss: 0.5876883268356323, Accuracy: 0.71875\n","Epoch 2, Batch 108/161, Loss: 0.5568172931671143, Accuracy: 0.75\n","Epoch 2, Batch 109/161, Loss: 0.6533589363098145, Accuracy: 0.625\n","Epoch 2, Batch 110/161, Loss: 0.5861752033233643, Accuracy: 0.71875\n","Epoch 2, Batch 111/161, Loss: 0.4746777415275574, Accuracy: 0.84375\n","Epoch 2, Batch 112/161, Loss: 0.536679744720459, Accuracy: 0.78125\n","Epoch 2, Batch 113/161, Loss: 0.45110124349594116, Accuracy: 0.84375\n","Epoch 2, Batch 114/161, Loss: 0.6908793449401855, Accuracy: 0.625\n","Epoch 2, Batch 115/161, Loss: 0.6992707252502441, Accuracy: 0.625\n","Epoch 2, Batch 116/161, Loss: 0.6255381107330322, Accuracy: 0.6875\n","Epoch 2, Batch 117/161, Loss: 0.5021350383758545, Accuracy: 0.8125\n","Epoch 2, Batch 118/161, Loss: 0.64347243309021, Accuracy: 0.65625\n","Epoch 2, Batch 119/161, Loss: 0.5673305988311768, Accuracy: 0.75\n","Epoch 2, Batch 120/161, Loss: 0.6880173683166504, Accuracy: 0.59375\n","Epoch 2, Batch 121/161, Loss: 0.508886456489563, Accuracy: 0.8125\n","Epoch 2, Batch 122/161, Loss: 0.6040778160095215, Accuracy: 0.6875\n","Epoch 2, Batch 123/161, Loss: 0.5139988660812378, Accuracy: 0.78125\n","Epoch 2, Batch 124/161, Loss: 0.5595613121986389, Accuracy: 0.75\n","Epoch 2, Batch 125/161, Loss: 0.7191948890686035, Accuracy: 0.59375\n","Epoch 2, Batch 126/161, Loss: 0.6430395841598511, Accuracy: 0.65625\n","Epoch 2, Batch 127/161, Loss: 0.5412665605545044, Accuracy: 0.78125\n","Epoch 2, Batch 128/161, Loss: 0.691087007522583, Accuracy: 0.59375\n","Epoch 2, Batch 129/161, Loss: 0.544029176235199, Accuracy: 0.78125\n","Epoch 2, Batch 130/161, Loss: 0.6110756993293762, Accuracy: 0.6875\n","Epoch 2, Batch 131/161, Loss: 0.5051654577255249, Accuracy: 0.8125\n","Epoch 2, Batch 132/161, Loss: 0.6529943943023682, Accuracy: 0.65625\n","Epoch 2, Batch 133/161, Loss: 0.6156167387962341, Accuracy: 0.6875\n","Epoch 2, Batch 134/161, Loss: 0.5849818587303162, Accuracy: 0.71875\n","Epoch 2, Batch 135/161, Loss: 0.5240894556045532, Accuracy: 0.78125\n","Epoch 2, Batch 136/161, Loss: 0.4894835948944092, Accuracy: 0.8125\n","Epoch 2, Batch 137/161, Loss: 0.6611143946647644, Accuracy: 0.625\n","Epoch 2, Batch 138/161, Loss: 0.5184868574142456, Accuracy: 0.78125\n","Epoch 2, Batch 139/161, Loss: 0.5386080145835876, Accuracy: 0.75\n","Epoch 2, Batch 140/161, Loss: 0.6733756065368652, Accuracy: 0.625\n","Epoch 2, Batch 141/161, Loss: 0.6186434626579285, Accuracy: 0.6875\n","Epoch 2, Batch 142/161, Loss: 0.5513780117034912, Accuracy: 0.75\n","Epoch 2, Batch 143/161, Loss: 0.5664942860603333, Accuracy: 0.6875\n","Epoch 2, Batch 144/161, Loss: 0.6345802545547485, Accuracy: 0.65625\n","Epoch 2, Batch 145/161, Loss: 0.5247779488563538, Accuracy: 0.78125\n","Epoch 2, Batch 146/161, Loss: 0.521436333656311, Accuracy: 0.78125\n","Epoch 2, Batch 147/161, Loss: 0.6471602916717529, Accuracy: 0.65625\n","Epoch 2, Batch 148/161, Loss: 0.6533271074295044, Accuracy: 0.65625\n","Epoch 2, Batch 149/161, Loss: 0.5546756982803345, Accuracy: 0.75\n","Epoch 2, Batch 150/161, Loss: 0.6992977857589722, Accuracy: 0.59375\n","Epoch 2, Batch 151/161, Loss: 0.6367502212524414, Accuracy: 0.65625\n","Epoch 2, Batch 152/161, Loss: 0.48356759548187256, Accuracy: 0.84375\n","Epoch 2, Batch 153/161, Loss: 0.6043683290481567, Accuracy: 0.6875\n","Epoch 2, Batch 154/161, Loss: 0.6201640367507935, Accuracy: 0.71875\n","Epoch 2, Batch 155/161, Loss: 0.6203641891479492, Accuracy: 0.6875\n","Epoch 2, Batch 156/161, Loss: 0.560185432434082, Accuracy: 0.75\n","Epoch 2, Batch 157/161, Loss: 0.5367955565452576, Accuracy: 0.78125\n","Epoch 2, Batch 158/161, Loss: 0.48131799697875977, Accuracy: 0.84375\n","Epoch 2, Batch 159/161, Loss: 0.5675984025001526, Accuracy: 0.71875\n","Epoch 2, Batch 160/161, Loss: 0.5241860151290894, Accuracy: 0.75\n","Epoch 2, Batch 161/161, Loss: 0.5171748995780945, Accuracy: 0.78125\n","Epoch 3, Batch 1/161, Loss: 0.5346571207046509, Accuracy: 0.75\n","Epoch 3, Batch 2/161, Loss: 0.7379322052001953, Accuracy: 0.59375\n","Epoch 3, Batch 3/161, Loss: 0.6339331865310669, Accuracy: 0.65625\n","Epoch 3, Batch 4/161, Loss: 0.6150608062744141, Accuracy: 0.65625\n","Epoch 3, Batch 5/161, Loss: 0.557125985622406, Accuracy: 0.75\n","Epoch 3, Batch 6/161, Loss: 0.6353129148483276, Accuracy: 0.65625\n","Epoch 3, Batch 7/161, Loss: 0.5909275412559509, Accuracy: 0.75\n","Epoch 3, Batch 8/161, Loss: 0.6289487481117249, Accuracy: 0.65625\n","Epoch 3, Batch 9/161, Loss: 0.6258670091629028, Accuracy: 0.65625\n","Epoch 3, Batch 10/161, Loss: 0.6804290413856506, Accuracy: 0.59375\n","Epoch 3, Batch 11/161, Loss: 0.5202898979187012, Accuracy: 0.8125\n","Epoch 3, Batch 12/161, Loss: 0.6275553107261658, Accuracy: 0.625\n","Epoch 3, Batch 13/161, Loss: 0.5818911790847778, Accuracy: 0.6875\n","Epoch 3, Batch 14/161, Loss: 0.6491477489471436, Accuracy: 0.625\n","Epoch 3, Batch 15/161, Loss: 0.6223258972167969, Accuracy: 0.65625\n","Epoch 3, Batch 16/161, Loss: 0.6617797613143921, Accuracy: 0.625\n","Epoch 3, Batch 17/161, Loss: 0.5769394636154175, Accuracy: 0.71875\n","Epoch 3, Batch 18/161, Loss: 0.5726912021636963, Accuracy: 0.75\n","Epoch 3, Batch 19/161, Loss: 0.6186426877975464, Accuracy: 0.65625\n","Epoch 3, Batch 20/161, Loss: 0.6242421865463257, Accuracy: 0.6875\n","Epoch 3, Batch 21/161, Loss: 0.6336925029754639, Accuracy: 0.65625\n","Epoch 3, Batch 22/161, Loss: 0.5775963068008423, Accuracy: 0.71875\n","Epoch 3, Batch 23/161, Loss: 0.5922669172286987, Accuracy: 0.65625\n","Epoch 3, Batch 24/161, Loss: 0.5075186491012573, Accuracy: 0.78125\n","Epoch 3, Batch 25/161, Loss: 0.5772405862808228, Accuracy: 0.71875\n","Epoch 3, Batch 26/161, Loss: 0.5849732756614685, Accuracy: 0.71875\n","Epoch 3, Batch 27/161, Loss: 0.4596932828426361, Accuracy: 0.84375\n","Epoch 3, Batch 28/161, Loss: 0.8215805888175964, Accuracy: 0.46875\n","Epoch 3, Batch 29/161, Loss: 0.5584040880203247, Accuracy: 0.71875\n","Epoch 3, Batch 30/161, Loss: 0.6290943622589111, Accuracy: 0.625\n","Epoch 3, Batch 31/161, Loss: 0.6320399045944214, Accuracy: 0.625\n","Epoch 3, Batch 32/161, Loss: 0.6197727918624878, Accuracy: 0.65625\n","Epoch 3, Batch 33/161, Loss: 0.515779972076416, Accuracy: 0.8125\n","Epoch 3, Batch 34/161, Loss: 0.5859992504119873, Accuracy: 0.6875\n","Epoch 3, Batch 35/161, Loss: 0.6193137764930725, Accuracy: 0.65625\n","Epoch 3, Batch 36/161, Loss: 0.4274762272834778, Accuracy: 0.90625\n","Epoch 3, Batch 37/161, Loss: 0.5123994946479797, Accuracy: 0.78125\n","Epoch 3, Batch 38/161, Loss: 0.5907569527626038, Accuracy: 0.6875\n","Epoch 3, Batch 39/161, Loss: 0.47880277037620544, Accuracy: 0.78125\n","Epoch 3, Batch 40/161, Loss: 0.5776491165161133, Accuracy: 0.6875\n","Epoch 3, Batch 41/161, Loss: 0.7811193466186523, Accuracy: 0.5625\n","Epoch 3, Batch 42/161, Loss: 0.5244393348693848, Accuracy: 0.75\n","Epoch 3, Batch 43/161, Loss: 0.5588573217391968, Accuracy: 0.75\n","Epoch 3, Batch 44/161, Loss: 0.5760874152183533, Accuracy: 0.71875\n","Epoch 3, Batch 45/161, Loss: 0.6055894494056702, Accuracy: 0.6875\n","Epoch 3, Batch 46/161, Loss: 0.6106560230255127, Accuracy: 0.625\n","Epoch 3, Batch 47/161, Loss: 0.6496489644050598, Accuracy: 0.59375\n","Epoch 3, Batch 48/161, Loss: 0.5498911738395691, Accuracy: 0.71875\n","Epoch 3, Batch 49/161, Loss: 0.674170970916748, Accuracy: 0.53125\n","Epoch 3, Batch 50/161, Loss: 0.5948284864425659, Accuracy: 0.65625\n","Epoch 3, Batch 51/161, Loss: 0.5735295414924622, Accuracy: 0.71875\n","Epoch 3, Batch 52/161, Loss: 0.5345593690872192, Accuracy: 0.75\n","Epoch 3, Batch 53/161, Loss: 0.5706427097320557, Accuracy: 0.6875\n","Epoch 3, Batch 54/161, Loss: 0.6692908406257629, Accuracy: 0.59375\n","Epoch 3, Batch 55/161, Loss: 0.5627624988555908, Accuracy: 0.71875\n","Epoch 3, Batch 56/161, Loss: 0.5307893753051758, Accuracy: 0.75\n","Epoch 3, Batch 57/161, Loss: 0.5510656833648682, Accuracy: 0.6875\n","Epoch 3, Batch 58/161, Loss: 0.5358272194862366, Accuracy: 0.75\n","Epoch 3, Batch 59/161, Loss: 0.46074843406677246, Accuracy: 0.78125\n","Epoch 3, Batch 60/161, Loss: 0.6055128574371338, Accuracy: 0.65625\n","Epoch 3, Batch 61/161, Loss: 0.6192343235015869, Accuracy: 0.71875\n","Epoch 3, Batch 62/161, Loss: 0.5386096239089966, Accuracy: 0.71875\n","Epoch 3, Batch 63/161, Loss: 0.5992258787155151, Accuracy: 0.6875\n","Epoch 3, Batch 64/161, Loss: 0.48336151242256165, Accuracy: 0.78125\n","Epoch 3, Batch 65/161, Loss: 0.49923890829086304, Accuracy: 0.78125\n","Epoch 3, Batch 66/161, Loss: 0.5193271636962891, Accuracy: 0.71875\n","Epoch 3, Batch 67/161, Loss: 0.5916682481765747, Accuracy: 0.65625\n","Epoch 3, Batch 68/161, Loss: 0.4859895408153534, Accuracy: 0.78125\n","Epoch 3, Batch 69/161, Loss: 0.48599517345428467, Accuracy: 0.78125\n","Epoch 3, Batch 70/161, Loss: 0.5710840225219727, Accuracy: 0.71875\n","Epoch 3, Batch 71/161, Loss: 0.5318397283554077, Accuracy: 0.71875\n","Epoch 3, Batch 72/161, Loss: 0.612933874130249, Accuracy: 0.6875\n","Epoch 3, Batch 73/161, Loss: 0.5039715766906738, Accuracy: 0.75\n","Epoch 3, Batch 74/161, Loss: 0.5370638370513916, Accuracy: 0.75\n","Epoch 3, Batch 75/161, Loss: 0.5044353604316711, Accuracy: 0.75\n","Epoch 3, Batch 76/161, Loss: 0.5163400173187256, Accuracy: 0.75\n","Epoch 3, Batch 77/161, Loss: 0.5020653009414673, Accuracy: 0.71875\n","Epoch 3, Batch 78/161, Loss: 0.5879932045936584, Accuracy: 0.6875\n","Epoch 3, Batch 79/161, Loss: 0.4354475140571594, Accuracy: 0.8125\n","Epoch 3, Batch 80/161, Loss: 0.5060356855392456, Accuracy: 0.78125\n","Epoch 3, Batch 81/161, Loss: 0.47346732020378113, Accuracy: 0.8125\n","Epoch 3, Batch 82/161, Loss: 0.5175056457519531, Accuracy: 0.71875\n","Epoch 3, Batch 83/161, Loss: 0.5210069417953491, Accuracy: 0.71875\n","Epoch 3, Batch 84/161, Loss: 0.5279812216758728, Accuracy: 0.71875\n","Epoch 3, Batch 85/161, Loss: 0.5879011154174805, Accuracy: 0.71875\n","Epoch 3, Batch 86/161, Loss: 0.5493884086608887, Accuracy: 0.71875\n","Epoch 3, Batch 87/161, Loss: 0.5231983661651611, Accuracy: 0.78125\n","Epoch 3, Batch 88/161, Loss: 0.5392881631851196, Accuracy: 0.71875\n","Epoch 3, Batch 89/161, Loss: 0.5165767669677734, Accuracy: 0.6875\n","Epoch 3, Batch 90/161, Loss: 0.5685690641403198, Accuracy: 0.75\n","Epoch 3, Batch 91/161, Loss: 0.5589269399642944, Accuracy: 0.6875\n","Epoch 3, Batch 92/161, Loss: 0.6704025268554688, Accuracy: 0.625\n","Epoch 3, Batch 93/161, Loss: 0.4903033375740051, Accuracy: 0.8125\n","Epoch 3, Batch 94/161, Loss: 0.5715017318725586, Accuracy: 0.65625\n","Epoch 3, Batch 95/161, Loss: 0.5165773034095764, Accuracy: 0.75\n","Epoch 3, Batch 96/161, Loss: 0.4511839747428894, Accuracy: 0.78125\n","Epoch 3, Batch 97/161, Loss: 0.4814833402633667, Accuracy: 0.78125\n","Epoch 3, Batch 98/161, Loss: 0.7143890857696533, Accuracy: 0.625\n","Epoch 3, Batch 99/161, Loss: 0.5520778894424438, Accuracy: 0.71875\n","Epoch 3, Batch 100/161, Loss: 0.5820931196212769, Accuracy: 0.6875\n","Epoch 3, Batch 101/161, Loss: 0.5716518759727478, Accuracy: 0.8125\n","Epoch 3, Batch 102/161, Loss: 0.6611793041229248, Accuracy: 0.5625\n","Epoch 3, Batch 103/161, Loss: 0.5827316641807556, Accuracy: 0.71875\n","Epoch 3, Batch 104/161, Loss: 0.5778268575668335, Accuracy: 0.6875\n","Epoch 3, Batch 105/161, Loss: 0.551288366317749, Accuracy: 0.75\n","Epoch 3, Batch 106/161, Loss: 0.597793698310852, Accuracy: 0.65625\n","Epoch 3, Batch 107/161, Loss: 0.5527958869934082, Accuracy: 0.71875\n","Epoch 3, Batch 108/161, Loss: 0.5062627792358398, Accuracy: 0.75\n","Epoch 3, Batch 109/161, Loss: 0.5652410984039307, Accuracy: 0.65625\n","Epoch 3, Batch 110/161, Loss: 0.5610324740409851, Accuracy: 0.71875\n","Epoch 3, Batch 111/161, Loss: 0.4008866548538208, Accuracy: 0.84375\n","Epoch 3, Batch 112/161, Loss: 0.5602490305900574, Accuracy: 0.78125\n","Epoch 3, Batch 113/161, Loss: 0.37731727957725525, Accuracy: 0.84375\n","Epoch 3, Batch 114/161, Loss: 0.5910608768463135, Accuracy: 0.65625\n","Epoch 3, Batch 115/161, Loss: 0.6604734659194946, Accuracy: 0.625\n","Epoch 3, Batch 116/161, Loss: 0.6216470003128052, Accuracy: 0.6875\n","Epoch 3, Batch 117/161, Loss: 0.4679628610610962, Accuracy: 0.8125\n","Epoch 3, Batch 118/161, Loss: 0.6114822626113892, Accuracy: 0.65625\n","Epoch 3, Batch 119/161, Loss: 0.5367450714111328, Accuracy: 0.75\n","Epoch 3, Batch 120/161, Loss: 0.6359249353408813, Accuracy: 0.59375\n","Epoch 3, Batch 121/161, Loss: 0.47292792797088623, Accuracy: 0.8125\n","Epoch 3, Batch 122/161, Loss: 0.5459107160568237, Accuracy: 0.6875\n","Epoch 3, Batch 123/161, Loss: 0.4261176586151123, Accuracy: 0.78125\n","Epoch 3, Batch 124/161, Loss: 0.5321056246757507, Accuracy: 0.75\n","Epoch 3, Batch 125/161, Loss: 0.7706752419471741, Accuracy: 0.59375\n","Epoch 3, Batch 126/161, Loss: 0.6005459427833557, Accuracy: 0.65625\n","Epoch 3, Batch 127/161, Loss: 0.5301574468612671, Accuracy: 0.78125\n","Epoch 3, Batch 128/161, Loss: 0.6447861194610596, Accuracy: 0.59375\n","Epoch 3, Batch 129/161, Loss: 0.5422956943511963, Accuracy: 0.78125\n","Epoch 3, Batch 130/161, Loss: 0.5822622776031494, Accuracy: 0.6875\n","Epoch 3, Batch 131/161, Loss: 0.4855705797672272, Accuracy: 0.8125\n","Epoch 3, Batch 132/161, Loss: 0.6363134384155273, Accuracy: 0.625\n","Epoch 3, Batch 133/161, Loss: 0.6024484634399414, Accuracy: 0.6875\n","Epoch 3, Batch 134/161, Loss: 0.5539182424545288, Accuracy: 0.75\n","Epoch 3, Batch 135/161, Loss: 0.4914317727088928, Accuracy: 0.78125\n","Epoch 3, Batch 136/161, Loss: 0.4505571126937866, Accuracy: 0.8125\n","Epoch 3, Batch 137/161, Loss: 0.5873329639434814, Accuracy: 0.625\n","Epoch 3, Batch 138/161, Loss: 0.4563167095184326, Accuracy: 0.78125\n","Epoch 3, Batch 139/161, Loss: 0.4427264332771301, Accuracy: 0.75\n","Epoch 3, Batch 140/161, Loss: 0.6256618499755859, Accuracy: 0.625\n","Epoch 3, Batch 141/161, Loss: 0.5522611737251282, Accuracy: 0.6875\n","Epoch 3, Batch 142/161, Loss: 0.47014495730400085, Accuracy: 0.75\n","Epoch 3, Batch 143/161, Loss: 0.4491329789161682, Accuracy: 0.71875\n","Epoch 3, Batch 144/161, Loss: 0.5797134637832642, Accuracy: 0.65625\n","Epoch 3, Batch 145/161, Loss: 0.47268223762512207, Accuracy: 0.84375\n","Epoch 3, Batch 146/161, Loss: 0.4430895745754242, Accuracy: 0.78125\n","Epoch 3, Batch 147/161, Loss: 0.5847275257110596, Accuracy: 0.65625\n","Epoch 3, Batch 148/161, Loss: 0.6050930023193359, Accuracy: 0.6875\n","Epoch 3, Batch 149/161, Loss: 0.47167131304740906, Accuracy: 0.75\n","Epoch 3, Batch 150/161, Loss: 0.6235828399658203, Accuracy: 0.625\n","Epoch 3, Batch 151/161, Loss: 0.6055222749710083, Accuracy: 0.65625\n","Epoch 3, Batch 152/161, Loss: 0.4008408784866333, Accuracy: 0.84375\n","Epoch 3, Batch 153/161, Loss: 0.5146496891975403, Accuracy: 0.75\n","Epoch 3, Batch 154/161, Loss: 0.7089194655418396, Accuracy: 0.71875\n","Epoch 3, Batch 155/161, Loss: 0.5811218023300171, Accuracy: 0.6875\n","Epoch 3, Batch 156/161, Loss: 0.5177629590034485, Accuracy: 0.71875\n","Epoch 3, Batch 157/161, Loss: 0.5245521664619446, Accuracy: 0.78125\n","Epoch 3, Batch 158/161, Loss: 0.5002392530441284, Accuracy: 0.84375\n","Epoch 3, Batch 159/161, Loss: 0.5014686584472656, Accuracy: 0.78125\n","Epoch 3, Batch 160/161, Loss: 0.40715712308883667, Accuracy: 0.78125\n","Epoch 3, Batch 161/161, Loss: 0.4761951267719269, Accuracy: 0.78125\n","Epoch 4, Batch 1/161, Loss: 0.42854341864585876, Accuracy: 0.75\n","Epoch 4, Batch 2/161, Loss: 0.7111216187477112, Accuracy: 0.5625\n","Epoch 4, Batch 3/161, Loss: 0.5589986443519592, Accuracy: 0.71875\n","Epoch 4, Batch 4/161, Loss: 0.5761608481407166, Accuracy: 0.65625\n","Epoch 4, Batch 5/161, Loss: 0.4918885827064514, Accuracy: 0.75\n","Epoch 4, Batch 6/161, Loss: 0.5989254713058472, Accuracy: 0.6875\n","Epoch 4, Batch 7/161, Loss: 0.5881485342979431, Accuracy: 0.75\n","Epoch 4, Batch 8/161, Loss: 0.5998910665512085, Accuracy: 0.6875\n","Epoch 4, Batch 9/161, Loss: 0.5530462265014648, Accuracy: 0.6875\n","Epoch 4, Batch 10/161, Loss: 0.6244401335716248, Accuracy: 0.59375\n","Epoch 4, Batch 11/161, Loss: 0.4786195755004883, Accuracy: 0.875\n","Epoch 4, Batch 12/161, Loss: 0.4986073970794678, Accuracy: 0.65625\n","Epoch 4, Batch 13/161, Loss: 0.48588675260543823, Accuracy: 0.6875\n","Epoch 4, Batch 14/161, Loss: 0.619953989982605, Accuracy: 0.625\n","Epoch 4, Batch 15/161, Loss: 0.5481418371200562, Accuracy: 0.6875\n","Epoch 4, Batch 16/161, Loss: 0.6547234058380127, Accuracy: 0.625\n","Epoch 4, Batch 17/161, Loss: 0.544579029083252, Accuracy: 0.75\n","Epoch 4, Batch 18/161, Loss: 0.5737459063529968, Accuracy: 0.75\n","Epoch 4, Batch 19/161, Loss: 0.5290261507034302, Accuracy: 0.75\n","Epoch 4, Batch 20/161, Loss: 0.6387102007865906, Accuracy: 0.65625\n","Epoch 4, Batch 21/161, Loss: 0.6149423122406006, Accuracy: 0.65625\n","Epoch 4, Batch 22/161, Loss: 0.5519062280654907, Accuracy: 0.78125\n","Epoch 4, Batch 23/161, Loss: 0.4950276017189026, Accuracy: 0.71875\n","Epoch 4, Batch 24/161, Loss: 0.4092048108577728, Accuracy: 0.84375\n","Epoch 4, Batch 25/161, Loss: 0.5369390845298767, Accuracy: 0.71875\n","Epoch 4, Batch 26/161, Loss: 0.6050491333007812, Accuracy: 0.75\n","Epoch 4, Batch 27/161, Loss: 0.4049970209598541, Accuracy: 0.84375\n","Epoch 4, Batch 28/161, Loss: 0.6523797512054443, Accuracy: 0.53125\n","Epoch 4, Batch 29/161, Loss: 0.48070651292800903, Accuracy: 0.71875\n","Epoch 4, Batch 30/161, Loss: 0.5944827795028687, Accuracy: 0.59375\n","Epoch 4, Batch 31/161, Loss: 0.5869021415710449, Accuracy: 0.6875\n","Epoch 4, Batch 32/161, Loss: 0.5664472579956055, Accuracy: 0.71875\n","Epoch 4, Batch 33/161, Loss: 0.4727299213409424, Accuracy: 0.8125\n","Epoch 4, Batch 34/161, Loss: 0.5175831317901611, Accuracy: 0.6875\n","Epoch 4, Batch 35/161, Loss: 0.5899066925048828, Accuracy: 0.6875\n","Epoch 4, Batch 36/161, Loss: 0.39127257466316223, Accuracy: 0.9375\n","Epoch 4, Batch 37/161, Loss: 0.44586890935897827, Accuracy: 0.78125\n","Epoch 4, Batch 38/161, Loss: 0.5415393114089966, Accuracy: 0.71875\n","Epoch 4, Batch 39/161, Loss: 0.3792511224746704, Accuracy: 0.84375\n","Epoch 4, Batch 40/161, Loss: 0.41221699118614197, Accuracy: 0.6875\n","Epoch 4, Batch 41/161, Loss: 0.7880905270576477, Accuracy: 0.59375\n","Epoch 4, Batch 42/161, Loss: 0.46376699209213257, Accuracy: 0.75\n","Epoch 4, Batch 43/161, Loss: 0.5102063417434692, Accuracy: 0.65625\n","Epoch 4, Batch 44/161, Loss: 0.5026547908782959, Accuracy: 0.6875\n","Epoch 4, Batch 45/161, Loss: 0.5270508527755737, Accuracy: 0.71875\n","Epoch 4, Batch 46/161, Loss: 0.5182310342788696, Accuracy: 0.6875\n","Epoch 4, Batch 47/161, Loss: 0.5499906539916992, Accuracy: 0.625\n","Epoch 4, Batch 48/161, Loss: 0.452705442905426, Accuracy: 0.78125\n","Epoch 4, Batch 49/161, Loss: 0.5324307680130005, Accuracy: 0.59375\n","Epoch 4, Batch 50/161, Loss: 0.5069682598114014, Accuracy: 0.71875\n","Epoch 4, Batch 51/161, Loss: 0.4876290559768677, Accuracy: 0.78125\n","Epoch 4, Batch 52/161, Loss: 0.42231833934783936, Accuracy: 0.8125\n","Epoch 4, Batch 53/161, Loss: 0.45943185687065125, Accuracy: 0.6875\n","Epoch 4, Batch 54/161, Loss: 0.6322345733642578, Accuracy: 0.59375\n","Epoch 4, Batch 55/161, Loss: 0.5235920548439026, Accuracy: 0.75\n","Epoch 4, Batch 56/161, Loss: 0.48194149136543274, Accuracy: 0.78125\n","Epoch 4, Batch 57/161, Loss: 0.4715740978717804, Accuracy: 0.71875\n","Epoch 4, Batch 58/161, Loss: 0.46306174993515015, Accuracy: 0.71875\n","Epoch 4, Batch 59/161, Loss: 0.34177812933921814, Accuracy: 0.875\n","Epoch 4, Batch 60/161, Loss: 0.462336927652359, Accuracy: 0.75\n","Epoch 4, Batch 61/161, Loss: 0.5656486749649048, Accuracy: 0.71875\n","Epoch 4, Batch 62/161, Loss: 0.4682047963142395, Accuracy: 0.71875\n","Epoch 4, Batch 63/161, Loss: 0.5414083003997803, Accuracy: 0.71875\n","Epoch 4, Batch 64/161, Loss: 0.39262592792510986, Accuracy: 0.84375\n","Epoch 4, Batch 65/161, Loss: 0.4081019461154938, Accuracy: 0.8125\n","Epoch 4, Batch 66/161, Loss: 0.41180360317230225, Accuracy: 0.84375\n","Epoch 4, Batch 67/161, Loss: 0.5262712240219116, Accuracy: 0.75\n","Epoch 4, Batch 68/161, Loss: 0.3795715570449829, Accuracy: 0.84375\n","Epoch 4, Batch 69/161, Loss: 0.43678876757621765, Accuracy: 0.8125\n","Epoch 4, Batch 70/161, Loss: 0.4631969928741455, Accuracy: 0.78125\n","Epoch 4, Batch 71/161, Loss: 0.46645742654800415, Accuracy: 0.84375\n","Epoch 4, Batch 72/161, Loss: 0.5553081035614014, Accuracy: 0.75\n","Epoch 4, Batch 73/161, Loss: 0.46384721994400024, Accuracy: 0.8125\n","Epoch 4, Batch 74/161, Loss: 0.462686687707901, Accuracy: 0.75\n","Epoch 4, Batch 75/161, Loss: 0.3975401222705841, Accuracy: 0.8125\n","Epoch 4, Batch 76/161, Loss: 0.43847858905792236, Accuracy: 0.78125\n","Epoch 4, Batch 77/161, Loss: 0.42316538095474243, Accuracy: 0.8125\n","Epoch 4, Batch 78/161, Loss: 0.5001585483551025, Accuracy: 0.78125\n","Epoch 4, Batch 79/161, Loss: 0.3219592273235321, Accuracy: 0.90625\n","Epoch 4, Batch 80/161, Loss: 0.416379451751709, Accuracy: 0.8125\n","Epoch 4, Batch 81/161, Loss: 0.4529513120651245, Accuracy: 0.8125\n","Epoch 4, Batch 82/161, Loss: 0.3784460425376892, Accuracy: 0.75\n","Epoch 4, Batch 83/161, Loss: 0.44454479217529297, Accuracy: 0.8125\n","Epoch 4, Batch 84/161, Loss: 0.3668639063835144, Accuracy: 0.84375\n","Epoch 4, Batch 85/161, Loss: 0.4921055734157562, Accuracy: 0.6875\n","Epoch 4, Batch 86/161, Loss: 0.5357294082641602, Accuracy: 0.6875\n","Epoch 4, Batch 87/161, Loss: 0.38528311252593994, Accuracy: 0.8125\n","Epoch 4, Batch 88/161, Loss: 0.4470914304256439, Accuracy: 0.71875\n","Epoch 4, Batch 89/161, Loss: 0.3580377697944641, Accuracy: 0.8125\n","Epoch 4, Batch 90/161, Loss: 0.5100127458572388, Accuracy: 0.75\n","Epoch 4, Batch 91/161, Loss: 0.44912904500961304, Accuracy: 0.78125\n","Epoch 4, Batch 92/161, Loss: 0.7011067867279053, Accuracy: 0.75\n","Epoch 4, Batch 93/161, Loss: 0.4101492762565613, Accuracy: 0.78125\n","Epoch 4, Batch 94/161, Loss: 0.5116910934448242, Accuracy: 0.78125\n","Epoch 4, Batch 95/161, Loss: 0.5062389373779297, Accuracy: 0.8125\n","Epoch 4, Batch 96/161, Loss: 0.41129082441329956, Accuracy: 0.84375\n","Epoch 4, Batch 97/161, Loss: 0.4295905530452728, Accuracy: 0.8125\n","Epoch 4, Batch 98/161, Loss: 0.4902375340461731, Accuracy: 0.75\n","Epoch 4, Batch 99/161, Loss: 0.599172830581665, Accuracy: 0.71875\n","Epoch 4, Batch 100/161, Loss: 0.5126534700393677, Accuracy: 0.75\n","Epoch 4, Batch 101/161, Loss: 0.48403918743133545, Accuracy: 0.78125\n","Epoch 4, Batch 102/161, Loss: 0.654880166053772, Accuracy: 0.59375\n","Epoch 4, Batch 103/161, Loss: 0.48362866044044495, Accuracy: 0.75\n","Epoch 4, Batch 104/161, Loss: 0.5010663270950317, Accuracy: 0.6875\n","Epoch 4, Batch 105/161, Loss: 0.4832155704498291, Accuracy: 0.75\n","Epoch 4, Batch 106/161, Loss: 0.5804716348648071, Accuracy: 0.65625\n","Epoch 4, Batch 107/161, Loss: 0.49168723821640015, Accuracy: 0.78125\n","Epoch 4, Batch 108/161, Loss: 0.42652618885040283, Accuracy: 0.84375\n","Epoch 4, Batch 109/161, Loss: 0.4364011585712433, Accuracy: 0.71875\n","Epoch 4, Batch 110/161, Loss: 0.5344705581665039, Accuracy: 0.75\n","Epoch 4, Batch 111/161, Loss: 0.3166119456291199, Accuracy: 0.875\n","Epoch 4, Batch 112/161, Loss: 0.4707852005958557, Accuracy: 0.78125\n","Epoch 4, Batch 113/161, Loss: 0.29377609491348267, Accuracy: 0.875\n","Epoch 4, Batch 114/161, Loss: 0.4817841947078705, Accuracy: 0.78125\n","Epoch 4, Batch 115/161, Loss: 0.620010495185852, Accuracy: 0.6875\n","Epoch 4, Batch 116/161, Loss: 0.586884617805481, Accuracy: 0.65625\n","Epoch 4, Batch 117/161, Loss: 0.4013896584510803, Accuracy: 0.875\n","Epoch 4, Batch 118/161, Loss: 0.5172003507614136, Accuracy: 0.71875\n","Epoch 4, Batch 119/161, Loss: 0.4767608344554901, Accuracy: 0.8125\n","Epoch 4, Batch 120/161, Loss: 0.5522623658180237, Accuracy: 0.6875\n","Epoch 4, Batch 121/161, Loss: 0.43937695026397705, Accuracy: 0.875\n","Epoch 4, Batch 122/161, Loss: 0.4809395670890808, Accuracy: 0.8125\n","Epoch 4, Batch 123/161, Loss: 0.3396105170249939, Accuracy: 0.90625\n","Epoch 4, Batch 124/161, Loss: 0.43856602907180786, Accuracy: 0.78125\n","Epoch 4, Batch 125/161, Loss: 0.7576978206634521, Accuracy: 0.625\n","Epoch 4, Batch 126/161, Loss: 0.564581036567688, Accuracy: 0.75\n","Epoch 4, Batch 127/161, Loss: 0.4552815854549408, Accuracy: 0.8125\n","Epoch 4, Batch 128/161, Loss: 0.6026023626327515, Accuracy: 0.65625\n","Epoch 4, Batch 129/161, Loss: 0.49300146102905273, Accuracy: 0.75\n","Epoch 4, Batch 130/161, Loss: 0.5339864492416382, Accuracy: 0.71875\n","Epoch 4, Batch 131/161, Loss: 0.4179527759552002, Accuracy: 0.84375\n","Epoch 4, Batch 132/161, Loss: 0.6077911853790283, Accuracy: 0.6875\n","Epoch 4, Batch 133/161, Loss: 0.5847330093383789, Accuracy: 0.75\n","Epoch 4, Batch 134/161, Loss: 0.5089986324310303, Accuracy: 0.78125\n","Epoch 4, Batch 135/161, Loss: 0.442227840423584, Accuracy: 0.78125\n","Epoch 4, Batch 136/161, Loss: 0.38816404342651367, Accuracy: 0.875\n","Epoch 4, Batch 137/161, Loss: 0.4674312472343445, Accuracy: 0.78125\n","Epoch 4, Batch 138/161, Loss: 0.39930227398872375, Accuracy: 0.8125\n","Epoch 4, Batch 139/161, Loss: 0.35264116525650024, Accuracy: 0.84375\n","Epoch 4, Batch 140/161, Loss: 0.5030726194381714, Accuracy: 0.78125\n","Epoch 4, Batch 141/161, Loss: 0.4862598776817322, Accuracy: 0.6875\n","Epoch 4, Batch 142/161, Loss: 0.3831294775009155, Accuracy: 0.8125\n","Epoch 4, Batch 143/161, Loss: 0.3613954782485962, Accuracy: 0.875\n","Epoch 4, Batch 144/161, Loss: 0.47308972477912903, Accuracy: 0.6875\n","Epoch 4, Batch 145/161, Loss: 0.44780027866363525, Accuracy: 0.84375\n","Epoch 4, Batch 146/161, Loss: 0.3935390114784241, Accuracy: 0.78125\n","Epoch 4, Batch 147/161, Loss: 0.5023044347763062, Accuracy: 0.6875\n","Epoch 4, Batch 148/161, Loss: 0.5001178979873657, Accuracy: 0.78125\n","Epoch 4, Batch 149/161, Loss: 0.3783245384693146, Accuracy: 0.875\n","Epoch 4, Batch 150/161, Loss: 0.5492085218429565, Accuracy: 0.65625\n","Epoch 4, Batch 151/161, Loss: 0.5075596570968628, Accuracy: 0.6875\n","Epoch 4, Batch 152/161, Loss: 0.3205728530883789, Accuracy: 0.84375\n","Epoch 4, Batch 153/161, Loss: 0.4431702792644501, Accuracy: 0.71875\n","Epoch 4, Batch 154/161, Loss: 0.601685106754303, Accuracy: 0.625\n","Epoch 4, Batch 155/161, Loss: 0.48129576444625854, Accuracy: 0.6875\n","Epoch 4, Batch 156/161, Loss: 0.4296782314777374, Accuracy: 0.75\n","Epoch 4, Batch 157/161, Loss: 0.4699521064758301, Accuracy: 0.8125\n","Epoch 4, Batch 158/161, Loss: 0.46752703189849854, Accuracy: 0.84375\n","Epoch 4, Batch 159/161, Loss: 0.3928193151950836, Accuracy: 0.875\n","Epoch 4, Batch 160/161, Loss: 0.3305611312389374, Accuracy: 0.84375\n","Epoch 4, Batch 161/161, Loss: 0.41032394766807556, Accuracy: 0.8125\n","Epoch 5, Batch 1/161, Loss: 0.3439635634422302, Accuracy: 0.84375\n","Epoch 5, Batch 2/161, Loss: 0.479850709438324, Accuracy: 0.71875\n","Epoch 5, Batch 3/161, Loss: 0.49343550205230713, Accuracy: 0.71875\n","Epoch 5, Batch 4/161, Loss: 0.49679359793663025, Accuracy: 0.75\n","Epoch 5, Batch 5/161, Loss: 0.422035813331604, Accuracy: 0.78125\n","Epoch 5, Batch 6/161, Loss: 0.5197263956069946, Accuracy: 0.71875\n","Epoch 5, Batch 7/161, Loss: 0.5577671527862549, Accuracy: 0.75\n","Epoch 5, Batch 8/161, Loss: 0.5713790655136108, Accuracy: 0.71875\n","Epoch 5, Batch 9/161, Loss: 0.5018315315246582, Accuracy: 0.71875\n","Epoch 5, Batch 10/161, Loss: 0.5583422780036926, Accuracy: 0.625\n","Epoch 5, Batch 11/161, Loss: 0.4632386565208435, Accuracy: 0.8125\n","Epoch 5, Batch 12/161, Loss: 0.4034114480018616, Accuracy: 0.8125\n","Epoch 5, Batch 13/161, Loss: 0.45080554485321045, Accuracy: 0.75\n","Epoch 5, Batch 14/161, Loss: 0.5023952126502991, Accuracy: 0.71875\n","Epoch 5, Batch 15/161, Loss: 0.47108209133148193, Accuracy: 0.78125\n","Epoch 5, Batch 16/161, Loss: 0.6382142305374146, Accuracy: 0.75\n","Epoch 5, Batch 17/161, Loss: 0.4997057616710663, Accuracy: 0.84375\n","Epoch 5, Batch 18/161, Loss: 0.5369153022766113, Accuracy: 0.78125\n","Epoch 5, Batch 19/161, Loss: 0.45107322931289673, Accuracy: 0.75\n","Epoch 5, Batch 20/161, Loss: 0.5331441164016724, Accuracy: 0.6875\n","Epoch 5, Batch 21/161, Loss: 0.5835160613059998, Accuracy: 0.75\n","Epoch 5, Batch 22/161, Loss: 0.4903075397014618, Accuracy: 0.8125\n","Epoch 5, Batch 23/161, Loss: 0.39340245723724365, Accuracy: 0.9375\n","Epoch 5, Batch 24/161, Loss: 0.3043413758277893, Accuracy: 0.9375\n","Epoch 5, Batch 25/161, Loss: 0.5089921355247498, Accuracy: 0.6875\n","Epoch 5, Batch 26/161, Loss: 0.5197340250015259, Accuracy: 0.84375\n","Epoch 5, Batch 27/161, Loss: 0.35610759258270264, Accuracy: 0.875\n","Epoch 5, Batch 28/161, Loss: 0.5191100239753723, Accuracy: 0.65625\n","Epoch 5, Batch 29/161, Loss: 0.39905253052711487, Accuracy: 0.78125\n","Epoch 5, Batch 30/161, Loss: 0.5611544847488403, Accuracy: 0.59375\n","Epoch 5, Batch 31/161, Loss: 0.5071173906326294, Accuracy: 0.75\n","Epoch 5, Batch 32/161, Loss: 0.4906051754951477, Accuracy: 0.8125\n","Epoch 5, Batch 33/161, Loss: 0.45605403184890747, Accuracy: 0.78125\n","Epoch 5, Batch 34/161, Loss: 0.4473620057106018, Accuracy: 0.78125\n","Epoch 5, Batch 35/161, Loss: 0.5457615852355957, Accuracy: 0.78125\n","Epoch 5, Batch 36/161, Loss: 0.3765049874782562, Accuracy: 0.875\n","Epoch 5, Batch 37/161, Loss: 0.3975943922996521, Accuracy: 0.78125\n","Epoch 5, Batch 38/161, Loss: 0.4880370795726776, Accuracy: 0.75\n","Epoch 5, Batch 39/161, Loss: 0.3138272166252136, Accuracy: 0.90625\n","Epoch 5, Batch 40/161, Loss: 0.3087362051010132, Accuracy: 0.84375\n","Epoch 5, Batch 41/161, Loss: 0.6575651168823242, Accuracy: 0.625\n","Epoch 5, Batch 42/161, Loss: 0.40653228759765625, Accuracy: 0.78125\n","Epoch 5, Batch 43/161, Loss: 0.5557811856269836, Accuracy: 0.6875\n","Epoch 5, Batch 44/161, Loss: 0.5025068521499634, Accuracy: 0.75\n","Epoch 5, Batch 45/161, Loss: 0.5507912635803223, Accuracy: 0.75\n","Epoch 5, Batch 46/161, Loss: 0.4796959459781647, Accuracy: 0.84375\n","Epoch 5, Batch 47/161, Loss: 0.5432208776473999, Accuracy: 0.78125\n","Epoch 5, Batch 48/161, Loss: 0.44711706042289734, Accuracy: 0.78125\n","Epoch 5, Batch 49/161, Loss: 0.4466284513473511, Accuracy: 0.875\n","Epoch 5, Batch 50/161, Loss: 0.4856678247451782, Accuracy: 0.84375\n","Epoch 5, Batch 51/161, Loss: 0.4294635057449341, Accuracy: 0.90625\n","Epoch 5, Batch 52/161, Loss: 0.3599860668182373, Accuracy: 0.84375\n","Epoch 5, Batch 53/161, Loss: 0.38861745595932007, Accuracy: 0.84375\n","Epoch 5, Batch 54/161, Loss: 0.45628926157951355, Accuracy: 0.78125\n","Epoch 5, Batch 55/161, Loss: 0.4696044921875, Accuracy: 0.78125\n","Epoch 5, Batch 56/161, Loss: 0.44669634103775024, Accuracy: 0.78125\n","Epoch 5, Batch 57/161, Loss: 0.40638449788093567, Accuracy: 0.8125\n","Epoch 5, Batch 58/161, Loss: 0.39578956365585327, Accuracy: 0.78125\n","Epoch 5, Batch 59/161, Loss: 0.2794193625450134, Accuracy: 0.90625\n","Epoch 5, Batch 60/161, Loss: 0.36186710000038147, Accuracy: 0.84375\n","Epoch 5, Batch 61/161, Loss: 0.48424822092056274, Accuracy: 0.8125\n","Epoch 5, Batch 62/161, Loss: 0.4036584794521332, Accuracy: 0.71875\n","Epoch 5, Batch 63/161, Loss: 0.4336182475090027, Accuracy: 0.78125\n","Epoch 5, Batch 64/161, Loss: 0.3622627854347229, Accuracy: 0.875\n","Epoch 5, Batch 65/161, Loss: 0.3473806381225586, Accuracy: 0.78125\n","Epoch 5, Batch 66/161, Loss: 0.30292531847953796, Accuracy: 0.9375\n","Epoch 5, Batch 67/161, Loss: 0.4611417353153229, Accuracy: 0.8125\n","Epoch 5, Batch 68/161, Loss: 0.31991851329803467, Accuracy: 0.875\n","Epoch 5, Batch 69/161, Loss: 0.33284324407577515, Accuracy: 0.84375\n","Epoch 5, Batch 70/161, Loss: 0.35708990693092346, Accuracy: 0.84375\n","Epoch 5, Batch 71/161, Loss: 0.4292171597480774, Accuracy: 0.84375\n","Epoch 5, Batch 72/161, Loss: 0.37991848587989807, Accuracy: 0.84375\n","Epoch 5, Batch 73/161, Loss: 0.42249757051467896, Accuracy: 0.875\n","Epoch 5, Batch 74/161, Loss: 0.4069211483001709, Accuracy: 0.71875\n","Epoch 5, Batch 75/161, Loss: 0.31841033697128296, Accuracy: 0.84375\n","Epoch 5, Batch 76/161, Loss: 0.3908340334892273, Accuracy: 0.8125\n","Epoch 5, Batch 77/161, Loss: 0.3702438771724701, Accuracy: 0.8125\n","Epoch 5, Batch 78/161, Loss: 0.42204487323760986, Accuracy: 0.78125\n","Epoch 5, Batch 79/161, Loss: 0.2532292604446411, Accuracy: 0.90625\n","Epoch 5, Batch 80/161, Loss: 0.3448109030723572, Accuracy: 0.84375\n","Epoch 5, Batch 81/161, Loss: 0.3828919231891632, Accuracy: 0.84375\n","Epoch 5, Batch 82/161, Loss: 0.3930180072784424, Accuracy: 0.8125\n","Epoch 5, Batch 83/161, Loss: 0.4385889172554016, Accuracy: 0.6875\n","Epoch 5, Batch 84/161, Loss: 0.3320406675338745, Accuracy: 0.90625\n","Epoch 5, Batch 85/161, Loss: 0.4502384066581726, Accuracy: 0.78125\n","Epoch 5, Batch 86/161, Loss: 0.5531996488571167, Accuracy: 0.65625\n","Epoch 5, Batch 87/161, Loss: 0.2935556173324585, Accuracy: 0.90625\n","Epoch 5, Batch 88/161, Loss: 0.38521599769592285, Accuracy: 0.75\n","Epoch 5, Batch 89/161, Loss: 0.29406166076660156, Accuracy: 0.875\n","Epoch 5, Batch 90/161, Loss: 0.39319321513175964, Accuracy: 0.84375\n","Epoch 5, Batch 91/161, Loss: 0.3673040270805359, Accuracy: 0.8125\n","Epoch 5, Batch 92/161, Loss: 0.6838709712028503, Accuracy: 0.8125\n","Epoch 5, Batch 93/161, Loss: 0.33455508947372437, Accuracy: 0.8125\n","Epoch 5, Batch 94/161, Loss: 0.4387083649635315, Accuracy: 0.84375\n","Epoch 5, Batch 95/161, Loss: 0.47127020359039307, Accuracy: 0.75\n","Epoch 5, Batch 96/161, Loss: 0.406991571187973, Accuracy: 0.8125\n","Epoch 5, Batch 97/161, Loss: 0.4346095025539398, Accuracy: 0.75\n","Epoch 5, Batch 98/161, Loss: 0.4024176001548767, Accuracy: 0.84375\n","Epoch 5, Batch 99/161, Loss: 0.4911022186279297, Accuracy: 0.84375\n","Epoch 5, Batch 100/161, Loss: 0.46948909759521484, Accuracy: 0.625\n","Epoch 5, Batch 101/161, Loss: 0.3885651230812073, Accuracy: 0.78125\n","Epoch 5, Batch 102/161, Loss: 0.6556233167648315, Accuracy: 0.71875\n","Epoch 5, Batch 103/161, Loss: 0.4122198820114136, Accuracy: 0.84375\n","Epoch 5, Batch 104/161, Loss: 0.4334205090999603, Accuracy: 0.75\n","Epoch 5, Batch 105/161, Loss: 0.44410911202430725, Accuracy: 0.75\n","Epoch 5, Batch 106/161, Loss: 0.5342085361480713, Accuracy: 0.75\n","Epoch 5, Batch 107/161, Loss: 0.4861012399196625, Accuracy: 0.6875\n","Epoch 5, Batch 108/161, Loss: 0.42343300580978394, Accuracy: 0.71875\n","Epoch 5, Batch 109/161, Loss: 0.3575209081172943, Accuracy: 0.84375\n","Epoch 5, Batch 110/161, Loss: 0.4699390232563019, Accuracy: 0.75\n","Epoch 5, Batch 111/161, Loss: 0.29009783267974854, Accuracy: 0.90625\n","Epoch 5, Batch 112/161, Loss: 0.3854954242706299, Accuracy: 0.84375\n","Epoch 5, Batch 113/161, Loss: 0.24527469277381897, Accuracy: 0.90625\n","Epoch 5, Batch 114/161, Loss: 0.3883324861526489, Accuracy: 0.78125\n","Epoch 5, Batch 115/161, Loss: 0.5627943277359009, Accuracy: 0.71875\n","Epoch 5, Batch 116/161, Loss: 0.54076087474823, Accuracy: 0.75\n","Epoch 5, Batch 117/161, Loss: 0.34985214471817017, Accuracy: 0.875\n","Epoch 5, Batch 118/161, Loss: 0.4406663775444031, Accuracy: 0.78125\n","Epoch 5, Batch 119/161, Loss: 0.4487844705581665, Accuracy: 0.90625\n","Epoch 5, Batch 120/161, Loss: 0.4733929932117462, Accuracy: 0.84375\n","Epoch 5, Batch 121/161, Loss: 0.4467872679233551, Accuracy: 0.84375\n","Epoch 5, Batch 122/161, Loss: 0.4609214663505554, Accuracy: 0.6875\n","Epoch 5, Batch 123/161, Loss: 0.31174731254577637, Accuracy: 0.90625\n","Epoch 5, Batch 124/161, Loss: 0.4085938334465027, Accuracy: 0.84375\n","Epoch 5, Batch 125/161, Loss: 0.505123496055603, Accuracy: 0.71875\n","Epoch 5, Batch 126/161, Loss: 0.5677312016487122, Accuracy: 0.78125\n","Epoch 5, Batch 127/161, Loss: 0.364801824092865, Accuracy: 0.84375\n","Epoch 5, Batch 128/161, Loss: 0.5429227352142334, Accuracy: 0.6875\n","Epoch 5, Batch 129/161, Loss: 0.45721524953842163, Accuracy: 0.78125\n","Epoch 5, Batch 130/161, Loss: 0.47983962297439575, Accuracy: 0.71875\n","Epoch 5, Batch 131/161, Loss: 0.34192541241645813, Accuracy: 0.84375\n","Epoch 5, Batch 132/161, Loss: 0.5758495330810547, Accuracy: 0.75\n","Epoch 5, Batch 133/161, Loss: 0.5356813669204712, Accuracy: 0.8125\n","Epoch 5, Batch 134/161, Loss: 0.4586368799209595, Accuracy: 0.78125\n","Epoch 5, Batch 135/161, Loss: 0.3729635775089264, Accuracy: 0.78125\n","Epoch 5, Batch 136/161, Loss: 0.29239052534103394, Accuracy: 0.90625\n","Epoch 5, Batch 137/161, Loss: 0.3472517132759094, Accuracy: 0.84375\n","Epoch 5, Batch 138/161, Loss: 0.38703155517578125, Accuracy: 0.8125\n","Epoch 5, Batch 139/161, Loss: 0.28471672534942627, Accuracy: 0.875\n","Epoch 5, Batch 140/161, Loss: 0.40116992592811584, Accuracy: 0.84375\n","Epoch 5, Batch 141/161, Loss: 0.4054596722126007, Accuracy: 0.71875\n","Epoch 5, Batch 142/161, Loss: 0.3427801728248596, Accuracy: 0.875\n","Epoch 5, Batch 143/161, Loss: 0.3000858426094055, Accuracy: 0.90625\n","Epoch 5, Batch 144/161, Loss: 0.3881930112838745, Accuracy: 0.8125\n","Epoch 5, Batch 145/161, Loss: 0.39936938881874084, Accuracy: 0.8125\n","Epoch 5, Batch 146/161, Loss: 0.3430548310279846, Accuracy: 0.78125\n","Epoch 5, Batch 147/161, Loss: 0.41390863060951233, Accuracy: 0.71875\n","Epoch 5, Batch 148/161, Loss: 0.4411472976207733, Accuracy: 0.71875\n","Epoch 5, Batch 149/161, Loss: 0.34990033507347107, Accuracy: 0.90625\n","Epoch 5, Batch 150/161, Loss: 0.4633772373199463, Accuracy: 0.75\n","Epoch 5, Batch 151/161, Loss: 0.38564130663871765, Accuracy: 0.78125\n","Epoch 5, Batch 152/161, Loss: 0.2657145857810974, Accuracy: 0.84375\n","Epoch 5, Batch 153/161, Loss: 0.37450462579727173, Accuracy: 0.6875\n","Epoch 5, Batch 154/161, Loss: 0.5720304250717163, Accuracy: 0.71875\n","Epoch 5, Batch 155/161, Loss: 0.4072485566139221, Accuracy: 0.71875\n","Epoch 5, Batch 156/161, Loss: 0.3900967836380005, Accuracy: 0.8125\n","Epoch 5, Batch 157/161, Loss: 0.41656169295310974, Accuracy: 0.75\n","Epoch 5, Batch 158/161, Loss: 0.403400719165802, Accuracy: 0.78125\n","Epoch 5, Batch 159/161, Loss: 0.250241219997406, Accuracy: 0.9375\n","Epoch 5, Batch 160/161, Loss: 0.22753411531448364, Accuracy: 0.90625\n","Epoch 5, Batch 161/161, Loss: 0.4040621519088745, Accuracy: 0.84375\n","Epoch 6, Batch 1/161, Loss: 0.19285473227500916, Accuracy: 0.9375\n","Epoch 6, Batch 2/161, Loss: 0.39292097091674805, Accuracy: 0.78125\n","Epoch 6, Batch 3/161, Loss: 0.3370990753173828, Accuracy: 0.875\n","Epoch 6, Batch 4/161, Loss: 0.41637587547302246, Accuracy: 0.71875\n","Epoch 6, Batch 5/161, Loss: 0.585146427154541, Accuracy: 0.78125\n","Epoch 6, Batch 6/161, Loss: 0.43950992822647095, Accuracy: 0.71875\n","Epoch 6, Batch 7/161, Loss: 0.5103671550750732, Accuracy: 0.78125\n","Epoch 6, Batch 8/161, Loss: 0.5590461492538452, Accuracy: 0.71875\n","Epoch 6, Batch 9/161, Loss: 0.4837152659893036, Accuracy: 0.71875\n","Epoch 6, Batch 10/161, Loss: 0.5185931921005249, Accuracy: 0.6875\n","Epoch 6, Batch 11/161, Loss: 0.5316915512084961, Accuracy: 0.65625\n","Epoch 6, Batch 12/161, Loss: 0.3691428601741791, Accuracy: 0.84375\n","Epoch 6, Batch 13/161, Loss: 0.44051575660705566, Accuracy: 0.75\n","Epoch 6, Batch 14/161, Loss: 0.4534927308559418, Accuracy: 0.78125\n","Epoch 6, Batch 15/161, Loss: 0.444099485874176, Accuracy: 0.84375\n","Epoch 6, Batch 16/161, Loss: 0.584668755531311, Accuracy: 0.6875\n","Epoch 6, Batch 17/161, Loss: 0.5160316824913025, Accuracy: 0.8125\n","Epoch 6, Batch 18/161, Loss: 0.5085632801055908, Accuracy: 0.75\n","Epoch 6, Batch 19/161, Loss: 0.42714178562164307, Accuracy: 0.8125\n","Epoch 6, Batch 20/161, Loss: 0.4665258228778839, Accuracy: 0.78125\n","Epoch 6, Batch 21/161, Loss: 0.5251029133796692, Accuracy: 0.6875\n","Epoch 6, Batch 22/161, Loss: 0.4263856112957001, Accuracy: 0.8125\n","Epoch 6, Batch 23/161, Loss: 0.33161649107933044, Accuracy: 0.9375\n","Epoch 6, Batch 24/161, Loss: 0.24575677514076233, Accuracy: 0.96875\n","Epoch 6, Batch 25/161, Loss: 0.4743303060531616, Accuracy: 0.78125\n","Epoch 6, Batch 26/161, Loss: 0.37937262654304504, Accuracy: 0.875\n","Epoch 6, Batch 27/161, Loss: 0.3071553707122803, Accuracy: 0.875\n","Epoch 6, Batch 28/161, Loss: 0.49233323335647583, Accuracy: 0.71875\n","Epoch 6, Batch 29/161, Loss: 0.35589176416397095, Accuracy: 0.8125\n","Epoch 6, Batch 30/161, Loss: 0.5316203832626343, Accuracy: 0.625\n","Epoch 6, Batch 31/161, Loss: 0.43768954277038574, Accuracy: 0.78125\n","Epoch 6, Batch 32/161, Loss: 0.4304918050765991, Accuracy: 0.84375\n","Epoch 6, Batch 33/161, Loss: 0.4323585629463196, Accuracy: 0.75\n","Epoch 6, Batch 34/161, Loss: 0.3942071199417114, Accuracy: 0.78125\n","Epoch 6, Batch 35/161, Loss: 0.4869333505630493, Accuracy: 0.8125\n","Epoch 6, Batch 36/161, Loss: 0.3924753963947296, Accuracy: 0.8125\n","Epoch 6, Batch 37/161, Loss: 0.3989579677581787, Accuracy: 0.78125\n","Epoch 6, Batch 38/161, Loss: 0.46910756826400757, Accuracy: 0.78125\n","Epoch 6, Batch 39/161, Loss: 0.2874578535556793, Accuracy: 0.875\n","Epoch 6, Batch 40/161, Loss: 0.26250123977661133, Accuracy: 0.9375\n","Epoch 6, Batch 41/161, Loss: 0.5187852382659912, Accuracy: 0.71875\n","Epoch 6, Batch 42/161, Loss: 0.27803242206573486, Accuracy: 0.90625\n","Epoch 6, Batch 43/161, Loss: 0.548053503036499, Accuracy: 0.75\n","Epoch 6, Batch 44/161, Loss: 0.4094970226287842, Accuracy: 0.71875\n","Epoch 6, Batch 45/161, Loss: 0.4748053550720215, Accuracy: 0.78125\n","Epoch 6, Batch 46/161, Loss: 0.43673694133758545, Accuracy: 0.84375\n","Epoch 6, Batch 47/161, Loss: 0.4936402440071106, Accuracy: 0.78125\n","Epoch 6, Batch 48/161, Loss: 0.4065871834754944, Accuracy: 0.78125\n","Epoch 6, Batch 49/161, Loss: 0.38978344202041626, Accuracy: 0.875\n","Epoch 6, Batch 50/161, Loss: 0.4589836597442627, Accuracy: 0.875\n","Epoch 6, Batch 51/161, Loss: 0.3964633345603943, Accuracy: 0.875\n","Epoch 6, Batch 52/161, Loss: 0.28740257024765015, Accuracy: 0.9375\n","Epoch 6, Batch 53/161, Loss: 0.3515660762786865, Accuracy: 0.8125\n","Epoch 6, Batch 54/161, Loss: 0.35608744621276855, Accuracy: 0.8125\n","Epoch 6, Batch 55/161, Loss: 0.3868001103401184, Accuracy: 0.84375\n","Epoch 6, Batch 56/161, Loss: 0.39246511459350586, Accuracy: 0.75\n","Epoch 6, Batch 57/161, Loss: 0.4189324378967285, Accuracy: 0.8125\n","Epoch 6, Batch 58/161, Loss: 0.3541982173919678, Accuracy: 0.75\n","Epoch 6, Batch 59/161, Loss: 0.2602141797542572, Accuracy: 0.90625\n","Epoch 6, Batch 60/161, Loss: 0.3185652196407318, Accuracy: 0.84375\n","Epoch 6, Batch 61/161, Loss: 0.46879756450653076, Accuracy: 0.8125\n","Epoch 6, Batch 62/161, Loss: 0.36565399169921875, Accuracy: 0.8125\n","Epoch 6, Batch 63/161, Loss: 0.4142875373363495, Accuracy: 0.84375\n","Epoch 6, Batch 64/161, Loss: 0.30894577503204346, Accuracy: 0.84375\n","Epoch 6, Batch 65/161, Loss: 0.28477513790130615, Accuracy: 0.875\n","Epoch 6, Batch 66/161, Loss: 0.27667751908302307, Accuracy: 0.9375\n","Epoch 6, Batch 67/161, Loss: 0.3657914996147156, Accuracy: 0.84375\n","Epoch 6, Batch 68/161, Loss: 0.31403064727783203, Accuracy: 0.875\n","Epoch 6, Batch 69/161, Loss: 0.30315935611724854, Accuracy: 0.84375\n","Epoch 6, Batch 70/161, Loss: 0.33475691080093384, Accuracy: 0.84375\n","Epoch 6, Batch 71/161, Loss: 0.42441117763519287, Accuracy: 0.71875\n","Epoch 6, Batch 72/161, Loss: 0.2998841404914856, Accuracy: 0.84375\n","Epoch 6, Batch 73/161, Loss: 0.3334590494632721, Accuracy: 0.90625\n","Epoch 6, Batch 74/161, Loss: 0.3703281283378601, Accuracy: 0.75\n","Epoch 6, Batch 75/161, Loss: 0.2982659339904785, Accuracy: 0.84375\n","Epoch 6, Batch 76/161, Loss: 0.30212557315826416, Accuracy: 0.8125\n","Epoch 6, Batch 77/161, Loss: 0.31890684366226196, Accuracy: 0.84375\n","Epoch 6, Batch 78/161, Loss: 0.5210569500923157, Accuracy: 0.78125\n","Epoch 6, Batch 79/161, Loss: 0.29795676469802856, Accuracy: 0.90625\n","Epoch 6, Batch 80/161, Loss: 0.41462308168411255, Accuracy: 0.84375\n","Epoch 6, Batch 81/161, Loss: 0.30798089504241943, Accuracy: 0.84375\n","Epoch 6, Batch 82/161, Loss: 0.26731666922569275, Accuracy: 0.875\n","Epoch 6, Batch 83/161, Loss: 0.4177898168563843, Accuracy: 0.8125\n","Epoch 6, Batch 84/161, Loss: 0.2368597388267517, Accuracy: 0.9375\n","Epoch 6, Batch 85/161, Loss: 0.449634850025177, Accuracy: 0.78125\n","Epoch 6, Batch 86/161, Loss: 0.5374685525894165, Accuracy: 0.625\n","Epoch 6, Batch 87/161, Loss: 0.26237747073173523, Accuracy: 0.90625\n","Epoch 6, Batch 88/161, Loss: 0.3979935646057129, Accuracy: 0.8125\n","Epoch 6, Batch 89/161, Loss: 0.23948493599891663, Accuracy: 0.9375\n","Epoch 6, Batch 90/161, Loss: 0.3245779275894165, Accuracy: 0.875\n","Epoch 6, Batch 91/161, Loss: 0.4718611538410187, Accuracy: 0.84375\n","Epoch 6, Batch 92/161, Loss: 0.4332069754600525, Accuracy: 0.875\n","Epoch 6, Batch 93/161, Loss: 0.4222475290298462, Accuracy: 0.8125\n","Epoch 6, Batch 94/161, Loss: 0.4345981478691101, Accuracy: 0.8125\n","Epoch 6, Batch 95/161, Loss: 0.41650402545928955, Accuracy: 0.75\n","Epoch 6, Batch 96/161, Loss: 0.3950744569301605, Accuracy: 0.84375\n","Epoch 6, Batch 97/161, Loss: 0.4738691449165344, Accuracy: 0.78125\n","Epoch 6, Batch 98/161, Loss: 0.383735716342926, Accuracy: 0.875\n","Epoch 6, Batch 99/161, Loss: 0.39663785696029663, Accuracy: 0.875\n","Epoch 6, Batch 100/161, Loss: 0.41546711325645447, Accuracy: 0.75\n","Epoch 6, Batch 101/161, Loss: 0.3108696937561035, Accuracy: 0.84375\n","Epoch 6, Batch 102/161, Loss: 0.5421764254570007, Accuracy: 0.71875\n","Epoch 6, Batch 103/161, Loss: 0.36851224303245544, Accuracy: 0.6875\n","Epoch 6, Batch 104/161, Loss: 0.38852912187576294, Accuracy: 0.8125\n","Epoch 6, Batch 105/161, Loss: 0.3853142261505127, Accuracy: 0.78125\n","Epoch 6, Batch 106/161, Loss: 0.4483632743358612, Accuracy: 0.71875\n","Epoch 6, Batch 107/161, Loss: 0.4895687699317932, Accuracy: 0.71875\n","Epoch 6, Batch 108/161, Loss: 0.41966712474823, Accuracy: 0.78125\n","Epoch 6, Batch 109/161, Loss: 0.3046113848686218, Accuracy: 0.9375\n","Epoch 6, Batch 110/161, Loss: 0.41133320331573486, Accuracy: 0.78125\n","Epoch 6, Batch 111/161, Loss: 0.27133709192276, Accuracy: 0.90625\n","Epoch 6, Batch 112/161, Loss: 0.3288998305797577, Accuracy: 0.875\n","Epoch 6, Batch 113/161, Loss: 0.1727961003780365, Accuracy: 1.0\n","Epoch 6, Batch 114/161, Loss: 0.35625016689300537, Accuracy: 0.78125\n","Epoch 6, Batch 115/161, Loss: 0.4541429579257965, Accuracy: 0.71875\n","Epoch 6, Batch 116/161, Loss: 0.4213240146636963, Accuracy: 0.84375\n","Epoch 6, Batch 117/161, Loss: 0.3134136497974396, Accuracy: 0.84375\n","Epoch 6, Batch 118/161, Loss: 0.32161134481430054, Accuracy: 0.90625\n","Epoch 6, Batch 119/161, Loss: 0.3533742129802704, Accuracy: 0.90625\n","Epoch 6, Batch 120/161, Loss: 0.4501721262931824, Accuracy: 0.84375\n","Epoch 6, Batch 121/161, Loss: 0.3894430994987488, Accuracy: 0.84375\n","Epoch 6, Batch 122/161, Loss: 0.41080036759376526, Accuracy: 0.75\n","Epoch 6, Batch 123/161, Loss: 0.2860981225967407, Accuracy: 0.8125\n","Epoch 6, Batch 124/161, Loss: 0.3839419484138489, Accuracy: 0.8125\n","Epoch 6, Batch 125/161, Loss: 0.4230046272277832, Accuracy: 0.71875\n","Epoch 6, Batch 126/161, Loss: 0.4995521903038025, Accuracy: 0.8125\n","Epoch 6, Batch 127/161, Loss: 0.32961413264274597, Accuracy: 0.8125\n","Epoch 6, Batch 128/161, Loss: 0.5099459290504456, Accuracy: 0.75\n","Epoch 6, Batch 129/161, Loss: 0.4338836967945099, Accuracy: 0.75\n","Epoch 6, Batch 130/161, Loss: 0.46163231134414673, Accuracy: 0.6875\n","Epoch 6, Batch 131/161, Loss: 0.3058975338935852, Accuracy: 0.875\n","Epoch 6, Batch 132/161, Loss: 0.5218037366867065, Accuracy: 0.75\n","Epoch 6, Batch 133/161, Loss: 0.4757046103477478, Accuracy: 0.8125\n","Epoch 6, Batch 134/161, Loss: 0.4255111813545227, Accuracy: 0.84375\n","Epoch 6, Batch 135/161, Loss: 0.3185940384864807, Accuracy: 0.875\n","Epoch 6, Batch 136/161, Loss: 0.2379515916109085, Accuracy: 0.9375\n","Epoch 6, Batch 137/161, Loss: 0.30897706747055054, Accuracy: 0.9375\n","Epoch 6, Batch 138/161, Loss: 0.3434543013572693, Accuracy: 0.84375\n","Epoch 6, Batch 139/161, Loss: 0.24950994551181793, Accuracy: 0.84375\n","Epoch 6, Batch 140/161, Loss: 0.2928946614265442, Accuracy: 0.90625\n","Epoch 6, Batch 141/161, Loss: 0.37478139996528625, Accuracy: 0.8125\n","Epoch 6, Batch 142/161, Loss: 0.30173230171203613, Accuracy: 0.90625\n","Epoch 6, Batch 143/161, Loss: 0.2727181315422058, Accuracy: 0.90625\n","Epoch 6, Batch 144/161, Loss: 0.33430179953575134, Accuracy: 0.84375\n","Epoch 6, Batch 145/161, Loss: 0.39288586378097534, Accuracy: 0.8125\n","Epoch 6, Batch 146/161, Loss: 0.3090265095233917, Accuracy: 0.78125\n","Epoch 6, Batch 147/161, Loss: 0.33761799335479736, Accuracy: 0.8125\n","Epoch 6, Batch 148/161, Loss: 0.3605665862560272, Accuracy: 0.78125\n","Epoch 6, Batch 149/161, Loss: 0.2882295846939087, Accuracy: 0.90625\n","Epoch 6, Batch 150/161, Loss: 0.4534417688846588, Accuracy: 0.78125\n","Epoch 6, Batch 151/161, Loss: 0.5072502493858337, Accuracy: 0.71875\n","Epoch 6, Batch 152/161, Loss: 0.27566444873809814, Accuracy: 0.875\n","Epoch 6, Batch 153/161, Loss: 0.4286484718322754, Accuracy: 0.8125\n","Epoch 6, Batch 154/161, Loss: 0.48754721879959106, Accuracy: 0.8125\n","Epoch 6, Batch 155/161, Loss: 0.40618979930877686, Accuracy: 0.78125\n","Epoch 6, Batch 156/161, Loss: 0.3773478865623474, Accuracy: 0.84375\n","Epoch 6, Batch 157/161, Loss: 0.3794313669204712, Accuracy: 0.8125\n","Epoch 6, Batch 158/161, Loss: 0.3276466131210327, Accuracy: 0.875\n","Epoch 6, Batch 159/161, Loss: 0.22513994574546814, Accuracy: 0.96875\n","Epoch 6, Batch 160/161, Loss: 0.17123791575431824, Accuracy: 0.96875\n","Epoch 6, Batch 161/161, Loss: 0.3374701142311096, Accuracy: 0.875\n","Epoch 7, Batch 1/161, Loss: 0.2319795787334442, Accuracy: 0.90625\n","Epoch 7, Batch 2/161, Loss: 0.34402352571487427, Accuracy: 0.84375\n","Epoch 7, Batch 3/161, Loss: 0.28954237699508667, Accuracy: 0.90625\n","Epoch 7, Batch 4/161, Loss: 0.3070589303970337, Accuracy: 0.84375\n","Epoch 7, Batch 5/161, Loss: 0.3257046341896057, Accuracy: 0.875\n","Epoch 7, Batch 6/161, Loss: 0.5881124138832092, Accuracy: 0.75\n","Epoch 7, Batch 7/161, Loss: 0.5200591087341309, Accuracy: 0.75\n","Epoch 7, Batch 8/161, Loss: 0.5109361410140991, Accuracy: 0.75\n","Epoch 7, Batch 9/161, Loss: 0.47099846601486206, Accuracy: 0.8125\n","Epoch 7, Batch 10/161, Loss: 0.5264997482299805, Accuracy: 0.71875\n","Epoch 7, Batch 11/161, Loss: 0.488336980342865, Accuracy: 0.6875\n","Epoch 7, Batch 12/161, Loss: 0.3374306261539459, Accuracy: 0.84375\n","Epoch 7, Batch 13/161, Loss: 0.40205681324005127, Accuracy: 0.78125\n","Epoch 7, Batch 14/161, Loss: 0.4113829433917999, Accuracy: 0.875\n","Epoch 7, Batch 15/161, Loss: 0.35935139656066895, Accuracy: 0.84375\n","Epoch 7, Batch 16/161, Loss: 0.6083468198776245, Accuracy: 0.65625\n","Epoch 7, Batch 17/161, Loss: 0.43509915471076965, Accuracy: 0.8125\n","Epoch 7, Batch 18/161, Loss: 0.4778664708137512, Accuracy: 0.6875\n","Epoch 7, Batch 19/161, Loss: 0.37964069843292236, Accuracy: 0.84375\n","Epoch 7, Batch 20/161, Loss: 0.48426496982574463, Accuracy: 0.75\n","Epoch 7, Batch 21/161, Loss: 0.48911595344543457, Accuracy: 0.8125\n","Epoch 7, Batch 22/161, Loss: 0.43026411533355713, Accuracy: 0.84375\n","Epoch 7, Batch 23/161, Loss: 0.30766069889068604, Accuracy: 0.96875\n","Epoch 7, Batch 24/161, Loss: 0.22458362579345703, Accuracy: 0.96875\n","Epoch 7, Batch 25/161, Loss: 0.4203726053237915, Accuracy: 0.71875\n","Epoch 7, Batch 26/161, Loss: 0.353836327791214, Accuracy: 0.90625\n","Epoch 7, Batch 27/161, Loss: 0.2600533366203308, Accuracy: 0.9375\n","Epoch 7, Batch 28/161, Loss: 0.373641699552536, Accuracy: 0.90625\n","Epoch 7, Batch 29/161, Loss: 0.29900968074798584, Accuracy: 0.875\n","Epoch 7, Batch 30/161, Loss: 0.6342223882675171, Accuracy: 0.625\n","Epoch 7, Batch 31/161, Loss: 0.3822866678237915, Accuracy: 0.875\n","Epoch 7, Batch 32/161, Loss: 0.31484049558639526, Accuracy: 0.90625\n","Epoch 7, Batch 33/161, Loss: 0.44620847702026367, Accuracy: 0.71875\n","Epoch 7, Batch 34/161, Loss: 0.3328683376312256, Accuracy: 0.84375\n","Epoch 7, Batch 35/161, Loss: 0.4367150664329529, Accuracy: 0.84375\n","Epoch 7, Batch 36/161, Loss: 0.35489916801452637, Accuracy: 0.84375\n","Epoch 7, Batch 37/161, Loss: 0.36056652665138245, Accuracy: 0.8125\n","Epoch 7, Batch 38/161, Loss: 0.44906121492385864, Accuracy: 0.75\n","Epoch 7, Batch 39/161, Loss: 0.2718346416950226, Accuracy: 0.875\n","Epoch 7, Batch 40/161, Loss: 0.25039729475975037, Accuracy: 0.9375\n","Epoch 7, Batch 41/161, Loss: 0.457059383392334, Accuracy: 0.78125\n","Epoch 7, Batch 42/161, Loss: 0.23968589305877686, Accuracy: 0.90625\n","Epoch 7, Batch 43/161, Loss: 0.29538339376449585, Accuracy: 0.875\n","Epoch 7, Batch 44/161, Loss: 0.6611237525939941, Accuracy: 0.71875\n","Epoch 7, Batch 45/161, Loss: 0.49900680780410767, Accuracy: 0.8125\n","Epoch 7, Batch 46/161, Loss: 0.5228537321090698, Accuracy: 0.78125\n","Epoch 7, Batch 47/161, Loss: 0.49575603008270264, Accuracy: 0.75\n","Epoch 7, Batch 48/161, Loss: 0.3424608111381531, Accuracy: 0.78125\n","Epoch 7, Batch 49/161, Loss: 0.3611069619655609, Accuracy: 0.84375\n","Epoch 7, Batch 50/161, Loss: 0.4548794627189636, Accuracy: 0.84375\n","Epoch 7, Batch 51/161, Loss: 0.4051133096218109, Accuracy: 0.84375\n","Epoch 7, Batch 52/161, Loss: 0.30786001682281494, Accuracy: 0.9375\n","Epoch 7, Batch 53/161, Loss: 0.36876389384269714, Accuracy: 0.84375\n","Epoch 7, Batch 54/161, Loss: 0.32211950421333313, Accuracy: 0.875\n","Epoch 7, Batch 55/161, Loss: 0.348189115524292, Accuracy: 0.90625\n","Epoch 7, Batch 56/161, Loss: 0.3653135895729065, Accuracy: 0.8125\n","Epoch 7, Batch 57/161, Loss: 0.34811267256736755, Accuracy: 0.875\n","Epoch 7, Batch 58/161, Loss: 0.5363960862159729, Accuracy: 0.75\n","Epoch 7, Batch 59/161, Loss: 0.1995626986026764, Accuracy: 0.90625\n","Epoch 7, Batch 60/161, Loss: 0.3385918140411377, Accuracy: 0.875\n","Epoch 7, Batch 61/161, Loss: 0.45475485920906067, Accuracy: 0.8125\n","Epoch 7, Batch 62/161, Loss: 0.3610265851020813, Accuracy: 0.84375\n","Epoch 7, Batch 63/161, Loss: 0.4784295856952667, Accuracy: 0.78125\n","Epoch 7, Batch 64/161, Loss: 0.3604520559310913, Accuracy: 0.8125\n","Epoch 7, Batch 65/161, Loss: 0.33104854822158813, Accuracy: 0.84375\n","Epoch 7, Batch 66/161, Loss: 0.2572733163833618, Accuracy: 0.96875\n","Epoch 7, Batch 67/161, Loss: 0.3279826045036316, Accuracy: 0.8125\n","Epoch 7, Batch 68/161, Loss: 0.29062843322753906, Accuracy: 0.875\n","Epoch 7, Batch 69/161, Loss: 0.39121633768081665, Accuracy: 0.8125\n","Epoch 7, Batch 70/161, Loss: 0.32064464688301086, Accuracy: 0.875\n","Epoch 7, Batch 71/161, Loss: 0.38532721996307373, Accuracy: 0.84375\n","Epoch 7, Batch 72/161, Loss: 0.3354019224643707, Accuracy: 0.84375\n","Epoch 7, Batch 73/161, Loss: 0.32274559140205383, Accuracy: 0.90625\n","Epoch 7, Batch 74/161, Loss: 0.35830551385879517, Accuracy: 0.8125\n","Epoch 7, Batch 75/161, Loss: 0.2946125864982605, Accuracy: 0.84375\n","Epoch 7, Batch 76/161, Loss: 0.310451865196228, Accuracy: 0.875\n","Epoch 7, Batch 77/161, Loss: 0.27757588028907776, Accuracy: 0.90625\n","Epoch 7, Batch 78/161, Loss: 0.3993426263332367, Accuracy: 0.75\n","Epoch 7, Batch 79/161, Loss: 0.24867574870586395, Accuracy: 0.9375\n","Epoch 7, Batch 80/161, Loss: 0.3740493357181549, Accuracy: 0.8125\n","Epoch 7, Batch 81/161, Loss: 0.2951527237892151, Accuracy: 0.84375\n","Epoch 7, Batch 82/161, Loss: 0.2645949125289917, Accuracy: 0.90625\n","Epoch 7, Batch 83/161, Loss: 0.3400685787200928, Accuracy: 0.8125\n","Epoch 7, Batch 84/161, Loss: 0.2324332296848297, Accuracy: 0.875\n","Epoch 7, Batch 85/161, Loss: 0.422202467918396, Accuracy: 0.75\n","Epoch 7, Batch 86/161, Loss: 0.5372774004936218, Accuracy: 0.59375\n","Epoch 7, Batch 87/161, Loss: 0.25168418884277344, Accuracy: 0.90625\n","Epoch 7, Batch 88/161, Loss: 0.37466129660606384, Accuracy: 0.8125\n","Epoch 7, Batch 89/161, Loss: 0.29525846242904663, Accuracy: 0.90625\n","Epoch 7, Batch 90/161, Loss: 0.23357300460338593, Accuracy: 0.90625\n","Epoch 7, Batch 91/161, Loss: 0.2719632685184479, Accuracy: 0.875\n","Epoch 7, Batch 92/161, Loss: 0.3161745071411133, Accuracy: 0.9375\n","Epoch 7, Batch 93/161, Loss: 0.35568904876708984, Accuracy: 0.90625\n","Epoch 7, Batch 94/161, Loss: 0.4662024676799774, Accuracy: 0.78125\n","Epoch 7, Batch 95/161, Loss: 0.38803786039352417, Accuracy: 0.78125\n","Epoch 7, Batch 96/161, Loss: 0.41149666905403137, Accuracy: 0.84375\n","Epoch 7, Batch 97/161, Loss: 0.48061496019363403, Accuracy: 0.71875\n","Epoch 7, Batch 98/161, Loss: 0.33848264813423157, Accuracy: 0.90625\n","Epoch 7, Batch 99/161, Loss: 0.38024604320526123, Accuracy: 0.78125\n","Epoch 7, Batch 100/161, Loss: 0.3619541823863983, Accuracy: 0.875\n","Epoch 7, Batch 101/161, Loss: 0.2876562476158142, Accuracy: 0.875\n","Epoch 7, Batch 102/161, Loss: 0.4389311969280243, Accuracy: 0.8125\n","Epoch 7, Batch 103/161, Loss: 0.2956690490245819, Accuracy: 0.90625\n","Epoch 7, Batch 104/161, Loss: 0.33103257417678833, Accuracy: 0.875\n","Epoch 7, Batch 105/161, Loss: 0.38022276759147644, Accuracy: 0.8125\n","Epoch 7, Batch 106/161, Loss: 0.42547717690467834, Accuracy: 0.71875\n","Epoch 7, Batch 107/161, Loss: 0.46744269132614136, Accuracy: 0.71875\n","Epoch 7, Batch 108/161, Loss: 0.38440126180648804, Accuracy: 0.84375\n","Epoch 7, Batch 109/161, Loss: 0.27869313955307007, Accuracy: 0.96875\n","Epoch 7, Batch 110/161, Loss: 0.40374240279197693, Accuracy: 0.78125\n","Epoch 7, Batch 111/161, Loss: 0.24020719528198242, Accuracy: 0.90625\n","Epoch 7, Batch 112/161, Loss: 0.29232800006866455, Accuracy: 0.875\n","Epoch 7, Batch 113/161, Loss: 0.18947859108448029, Accuracy: 0.96875\n","Epoch 7, Batch 114/161, Loss: 0.2915947437286377, Accuracy: 0.90625\n","Epoch 7, Batch 115/161, Loss: 0.3755991756916046, Accuracy: 0.78125\n","Epoch 7, Batch 116/161, Loss: 0.36133843660354614, Accuracy: 0.8125\n","Epoch 7, Batch 117/161, Loss: 0.2266635000705719, Accuracy: 0.90625\n","Epoch 7, Batch 118/161, Loss: 0.2788413166999817, Accuracy: 0.84375\n","Epoch 7, Batch 119/161, Loss: 0.31748270988464355, Accuracy: 0.90625\n","Epoch 7, Batch 120/161, Loss: 0.341221421957016, Accuracy: 0.84375\n","Epoch 7, Batch 121/161, Loss: 0.4829084873199463, Accuracy: 0.8125\n","Epoch 7, Batch 122/161, Loss: 0.47867316007614136, Accuracy: 0.75\n","Epoch 7, Batch 123/161, Loss: 0.27578112483024597, Accuracy: 0.90625\n","Epoch 7, Batch 124/161, Loss: 0.3868001699447632, Accuracy: 0.8125\n","Epoch 7, Batch 125/161, Loss: 0.39815711975097656, Accuracy: 0.8125\n","Epoch 7, Batch 126/161, Loss: 0.4276141822338104, Accuracy: 0.75\n","Epoch 7, Batch 127/161, Loss: 0.3092693090438843, Accuracy: 0.84375\n","Epoch 7, Batch 128/161, Loss: 0.46302342414855957, Accuracy: 0.78125\n","Epoch 7, Batch 129/161, Loss: 0.3953052759170532, Accuracy: 0.78125\n","Epoch 7, Batch 130/161, Loss: 0.4553011953830719, Accuracy: 0.71875\n","Epoch 7, Batch 131/161, Loss: 0.28357359766960144, Accuracy: 0.875\n","Epoch 7, Batch 132/161, Loss: 0.48104456067085266, Accuracy: 0.78125\n","Epoch 7, Batch 133/161, Loss: 0.4248037338256836, Accuracy: 0.875\n","Epoch 7, Batch 134/161, Loss: 0.4498900771141052, Accuracy: 0.84375\n","Epoch 7, Batch 135/161, Loss: 0.3241419196128845, Accuracy: 0.875\n","Epoch 7, Batch 136/161, Loss: 0.2163815200328827, Accuracy: 0.9375\n","Epoch 7, Batch 137/161, Loss: 0.29173338413238525, Accuracy: 0.90625\n","Epoch 7, Batch 138/161, Loss: 0.32537978887557983, Accuracy: 0.84375\n","Epoch 7, Batch 139/161, Loss: 0.2353903204202652, Accuracy: 0.90625\n","Epoch 7, Batch 140/161, Loss: 0.24908027052879333, Accuracy: 0.90625\n","Epoch 7, Batch 141/161, Loss: 0.3028438091278076, Accuracy: 0.8125\n","Epoch 7, Batch 142/161, Loss: 0.3167131841182709, Accuracy: 0.90625\n","Epoch 7, Batch 143/161, Loss: 0.21711993217468262, Accuracy: 0.90625\n","Epoch 7, Batch 144/161, Loss: 0.302578330039978, Accuracy: 0.875\n","Epoch 7, Batch 145/161, Loss: 0.33957141637802124, Accuracy: 0.90625\n","Epoch 7, Batch 146/161, Loss: 0.3142659366130829, Accuracy: 0.78125\n","Epoch 7, Batch 147/161, Loss: 0.3124896287918091, Accuracy: 0.84375\n","Epoch 7, Batch 148/161, Loss: 0.3516542911529541, Accuracy: 0.8125\n","Epoch 7, Batch 149/161, Loss: 0.29945188760757446, Accuracy: 0.90625\n","Epoch 7, Batch 150/161, Loss: 0.407226026058197, Accuracy: 0.78125\n","Epoch 7, Batch 151/161, Loss: 0.29367366433143616, Accuracy: 0.8125\n","Epoch 7, Batch 152/161, Loss: 0.2322114259004593, Accuracy: 0.84375\n","Epoch 7, Batch 153/161, Loss: 0.413088858127594, Accuracy: 0.875\n","Epoch 7, Batch 154/161, Loss: 0.5147377252578735, Accuracy: 0.78125\n","Epoch 7, Batch 155/161, Loss: 0.3925487995147705, Accuracy: 0.71875\n","Epoch 7, Batch 156/161, Loss: 0.34853941202163696, Accuracy: 0.8125\n","Epoch 7, Batch 157/161, Loss: 0.3254529535770416, Accuracy: 0.8125\n","Epoch 7, Batch 158/161, Loss: 0.32199910283088684, Accuracy: 0.84375\n","Epoch 7, Batch 159/161, Loss: 0.2359011471271515, Accuracy: 1.0\n","Epoch 7, Batch 160/161, Loss: 0.13322971761226654, Accuracy: 0.96875\n","Epoch 7, Batch 161/161, Loss: 0.24679365754127502, Accuracy: 0.9375\n","Epoch 8, Batch 1/161, Loss: 0.18511386215686798, Accuracy: 0.96875\n","Epoch 8, Batch 2/161, Loss: 0.23200348019599915, Accuracy: 0.9375\n","Epoch 8, Batch 3/161, Loss: 0.27570483088493347, Accuracy: 0.90625\n","Epoch 8, Batch 4/161, Loss: 0.2686458230018616, Accuracy: 0.875\n","Epoch 8, Batch 5/161, Loss: 0.21598570048809052, Accuracy: 0.9375\n","Epoch 8, Batch 6/161, Loss: 0.3077317178249359, Accuracy: 0.84375\n","Epoch 8, Batch 7/161, Loss: 0.3564329445362091, Accuracy: 0.8125\n","Epoch 8, Batch 8/161, Loss: 0.5447489023208618, Accuracy: 0.78125\n","Epoch 8, Batch 9/161, Loss: 0.47979217767715454, Accuracy: 0.8125\n","Epoch 8, Batch 10/161, Loss: 0.5034056901931763, Accuracy: 0.6875\n","Epoch 8, Batch 11/161, Loss: 0.4573357105255127, Accuracy: 0.78125\n","Epoch 8, Batch 12/161, Loss: 0.3245322108268738, Accuracy: 0.84375\n","Epoch 8, Batch 13/161, Loss: 0.3926613926887512, Accuracy: 0.78125\n","Epoch 8, Batch 14/161, Loss: 0.4004748463630676, Accuracy: 0.78125\n","Epoch 8, Batch 15/161, Loss: 0.38510242104530334, Accuracy: 0.875\n","Epoch 8, Batch 16/161, Loss: 0.49404585361480713, Accuracy: 0.75\n","Epoch 8, Batch 17/161, Loss: 0.41964197158813477, Accuracy: 0.78125\n","Epoch 8, Batch 18/161, Loss: 0.41915178298950195, Accuracy: 0.78125\n","Epoch 8, Batch 19/161, Loss: 0.33116480708122253, Accuracy: 0.78125\n","Epoch 8, Batch 20/161, Loss: 0.41672325134277344, Accuracy: 0.78125\n","Epoch 8, Batch 21/161, Loss: 0.4339638352394104, Accuracy: 0.78125\n","Epoch 8, Batch 22/161, Loss: 0.38320255279541016, Accuracy: 0.8125\n","Epoch 8, Batch 23/161, Loss: 0.2677783966064453, Accuracy: 1.0\n","Epoch 8, Batch 24/161, Loss: 0.2010989785194397, Accuracy: 0.9375\n","Epoch 8, Batch 25/161, Loss: 0.3608402609825134, Accuracy: 0.78125\n","Epoch 8, Batch 26/161, Loss: 0.34276312589645386, Accuracy: 0.875\n","Epoch 8, Batch 27/161, Loss: 0.2886429727077484, Accuracy: 0.90625\n","Epoch 8, Batch 28/161, Loss: 0.35347968339920044, Accuracy: 0.90625\n","Epoch 8, Batch 29/161, Loss: 0.268801748752594, Accuracy: 0.90625\n","Epoch 8, Batch 30/161, Loss: 0.4724138081073761, Accuracy: 0.65625\n","Epoch 8, Batch 31/161, Loss: 0.3660874366760254, Accuracy: 0.875\n","Epoch 8, Batch 32/161, Loss: 0.2860430181026459, Accuracy: 0.875\n","Epoch 8, Batch 33/161, Loss: 0.3978011906147003, Accuracy: 0.78125\n","Epoch 8, Batch 34/161, Loss: 0.29559487104415894, Accuracy: 0.84375\n","Epoch 8, Batch 35/161, Loss: 0.3970935344696045, Accuracy: 0.875\n","Epoch 8, Batch 36/161, Loss: 0.34446582198143005, Accuracy: 0.8125\n","Epoch 8, Batch 37/161, Loss: 0.36515337228775024, Accuracy: 0.84375\n","Epoch 8, Batch 38/161, Loss: 0.4656306505203247, Accuracy: 0.78125\n","Epoch 8, Batch 39/161, Loss: 0.28108805418014526, Accuracy: 0.875\n","Epoch 8, Batch 40/161, Loss: 0.254256933927536, Accuracy: 0.90625\n","Epoch 8, Batch 41/161, Loss: 0.42247816920280457, Accuracy: 0.78125\n","Epoch 8, Batch 42/161, Loss: 0.27576255798339844, Accuracy: 0.875\n","Epoch 8, Batch 43/161, Loss: 0.2734546363353729, Accuracy: 0.84375\n","Epoch 8, Batch 44/161, Loss: 0.4307278096675873, Accuracy: 0.84375\n","Epoch 8, Batch 45/161, Loss: 0.4006608724594116, Accuracy: 0.8125\n","Epoch 8, Batch 46/161, Loss: 0.3887597620487213, Accuracy: 0.84375\n","Epoch 8, Batch 47/161, Loss: 0.37822139263153076, Accuracy: 0.875\n","Epoch 8, Batch 48/161, Loss: 0.305736780166626, Accuracy: 0.875\n","Epoch 8, Batch 49/161, Loss: 0.381056010723114, Accuracy: 0.875\n","Epoch 8, Batch 50/161, Loss: 0.38296008110046387, Accuracy: 0.84375\n","Epoch 8, Batch 51/161, Loss: 0.33651989698410034, Accuracy: 0.90625\n","Epoch 8, Batch 52/161, Loss: 0.27593299746513367, Accuracy: 0.90625\n","Epoch 8, Batch 53/161, Loss: 0.3538212180137634, Accuracy: 0.8125\n","Epoch 8, Batch 54/161, Loss: 0.2600992023944855, Accuracy: 0.90625\n","Epoch 8, Batch 55/161, Loss: 0.32449960708618164, Accuracy: 0.90625\n","Epoch 8, Batch 56/161, Loss: 0.3361753225326538, Accuracy: 0.78125\n","Epoch 8, Batch 57/161, Loss: 0.3170859217643738, Accuracy: 0.875\n","Epoch 8, Batch 58/161, Loss: 0.5539224147796631, Accuracy: 0.75\n","Epoch 8, Batch 59/161, Loss: 0.171452596783638, Accuracy: 0.90625\n","Epoch 8, Batch 60/161, Loss: 0.2879561185836792, Accuracy: 0.84375\n","Epoch 8, Batch 61/161, Loss: 0.42189422249794006, Accuracy: 0.8125\n","Epoch 8, Batch 62/161, Loss: 0.33979111909866333, Accuracy: 0.84375\n","Epoch 8, Batch 63/161, Loss: 0.3893301486968994, Accuracy: 0.84375\n","Epoch 8, Batch 64/161, Loss: 0.3783901333808899, Accuracy: 0.8125\n","Epoch 8, Batch 65/161, Loss: 0.3022738993167877, Accuracy: 0.8125\n","Epoch 8, Batch 66/161, Loss: 0.24097199738025665, Accuracy: 0.96875\n","Epoch 8, Batch 67/161, Loss: 0.2778540253639221, Accuracy: 0.90625\n","Epoch 8, Batch 68/161, Loss: 0.2836228609085083, Accuracy: 0.84375\n","Epoch 8, Batch 69/161, Loss: 0.21614035964012146, Accuracy: 0.90625\n","Epoch 8, Batch 70/161, Loss: 0.314628541469574, Accuracy: 0.8125\n","Epoch 8, Batch 71/161, Loss: 0.3397667407989502, Accuracy: 0.84375\n","Epoch 8, Batch 72/161, Loss: 0.31525158882141113, Accuracy: 0.84375\n","Epoch 8, Batch 73/161, Loss: 0.3054101765155792, Accuracy: 0.90625\n","Epoch 8, Batch 74/161, Loss: 0.35546451807022095, Accuracy: 0.78125\n","Epoch 8, Batch 75/161, Loss: 0.2627844214439392, Accuracy: 0.875\n","Epoch 8, Batch 76/161, Loss: 0.25537219643592834, Accuracy: 0.90625\n","Epoch 8, Batch 77/161, Loss: 0.24611198902130127, Accuracy: 0.875\n","Epoch 8, Batch 78/161, Loss: 0.41446220874786377, Accuracy: 0.75\n","Epoch 8, Batch 79/161, Loss: 0.2622864246368408, Accuracy: 0.90625\n","Epoch 8, Batch 80/161, Loss: 0.4230850636959076, Accuracy: 0.8125\n","Epoch 8, Batch 81/161, Loss: 0.27628424763679504, Accuracy: 0.875\n","Epoch 8, Batch 82/161, Loss: 0.2234676629304886, Accuracy: 0.90625\n","Epoch 8, Batch 83/161, Loss: 0.33238181471824646, Accuracy: 0.8125\n","Epoch 8, Batch 84/161, Loss: 0.2580772042274475, Accuracy: 0.90625\n","Epoch 8, Batch 85/161, Loss: 0.37460988759994507, Accuracy: 0.78125\n","Epoch 8, Batch 86/161, Loss: 0.5496859550476074, Accuracy: 0.625\n","Epoch 8, Batch 87/161, Loss: 0.24810495972633362, Accuracy: 0.875\n","Epoch 8, Batch 88/161, Loss: 0.3991744816303253, Accuracy: 0.8125\n","Epoch 8, Batch 89/161, Loss: 0.2525056004524231, Accuracy: 0.90625\n","Epoch 8, Batch 90/161, Loss: 0.23633210361003876, Accuracy: 0.90625\n","Epoch 8, Batch 91/161, Loss: 0.2677978277206421, Accuracy: 0.84375\n","Epoch 8, Batch 92/161, Loss: 0.35277625918388367, Accuracy: 0.90625\n","Epoch 8, Batch 93/161, Loss: 0.3306954801082611, Accuracy: 0.90625\n","Epoch 8, Batch 94/161, Loss: 0.2570229172706604, Accuracy: 0.84375\n","Epoch 8, Batch 95/161, Loss: 0.3110083341598511, Accuracy: 0.8125\n","Epoch 8, Batch 96/161, Loss: 0.40032124519348145, Accuracy: 0.84375\n","Epoch 8, Batch 97/161, Loss: 0.47065454721450806, Accuracy: 0.78125\n","Epoch 8, Batch 98/161, Loss: 0.30477797985076904, Accuracy: 0.84375\n","Epoch 8, Batch 99/161, Loss: 0.3744773268699646, Accuracy: 0.8125\n","Epoch 8, Batch 100/161, Loss: 0.3007126450538635, Accuracy: 0.84375\n","Epoch 8, Batch 101/161, Loss: 0.28811439871788025, Accuracy: 0.875\n","Epoch 8, Batch 102/161, Loss: 0.44522958993911743, Accuracy: 0.78125\n","Epoch 8, Batch 103/161, Loss: 0.2730880677700043, Accuracy: 0.90625\n","Epoch 8, Batch 104/161, Loss: 0.3320554494857788, Accuracy: 0.8125\n","Epoch 8, Batch 105/161, Loss: 0.2557017505168915, Accuracy: 0.84375\n","Epoch 8, Batch 106/161, Loss: 0.36554503440856934, Accuracy: 0.8125\n","Epoch 8, Batch 107/161, Loss: 0.46018287539482117, Accuracy: 0.71875\n","Epoch 8, Batch 108/161, Loss: 0.315082848072052, Accuracy: 0.84375\n","Epoch 8, Batch 109/161, Loss: 0.24413776397705078, Accuracy: 0.9375\n","Epoch 8, Batch 110/161, Loss: 0.406673789024353, Accuracy: 0.78125\n","Epoch 8, Batch 111/161, Loss: 0.18550316989421844, Accuracy: 0.96875\n","Epoch 8, Batch 112/161, Loss: 0.27449288964271545, Accuracy: 0.90625\n","Epoch 8, Batch 113/161, Loss: 0.19823014736175537, Accuracy: 0.9375\n","Epoch 8, Batch 114/161, Loss: 0.266018271446228, Accuracy: 0.90625\n","Epoch 8, Batch 115/161, Loss: 0.3711839020252228, Accuracy: 0.8125\n","Epoch 8, Batch 116/161, Loss: 0.3391018509864807, Accuracy: 0.90625\n","Epoch 8, Batch 117/161, Loss: 0.1709047257900238, Accuracy: 0.96875\n","Epoch 8, Batch 118/161, Loss: 0.24976223707199097, Accuracy: 0.84375\n","Epoch 8, Batch 119/161, Loss: 0.24818235635757446, Accuracy: 0.90625\n","Epoch 8, Batch 120/161, Loss: 0.29232358932495117, Accuracy: 0.875\n","Epoch 8, Batch 121/161, Loss: 0.43326544761657715, Accuracy: 0.875\n","Epoch 8, Batch 122/161, Loss: 0.4380865693092346, Accuracy: 0.8125\n","Epoch 8, Batch 123/161, Loss: 0.31560173630714417, Accuracy: 0.875\n","Epoch 8, Batch 124/161, Loss: 0.3830457329750061, Accuracy: 0.8125\n","Epoch 8, Batch 125/161, Loss: 0.38895756006240845, Accuracy: 0.78125\n","Epoch 8, Batch 126/161, Loss: 0.3782985210418701, Accuracy: 0.84375\n","Epoch 8, Batch 127/161, Loss: 0.29566168785095215, Accuracy: 0.875\n","Epoch 8, Batch 128/161, Loss: 0.39887458086013794, Accuracy: 0.8125\n","Epoch 8, Batch 129/161, Loss: 0.37348672747612, Accuracy: 0.8125\n","Epoch 8, Batch 130/161, Loss: 0.40167635679244995, Accuracy: 0.75\n","Epoch 8, Batch 131/161, Loss: 0.2225729525089264, Accuracy: 0.90625\n","Epoch 8, Batch 132/161, Loss: 0.43463557958602905, Accuracy: 0.78125\n","Epoch 8, Batch 133/161, Loss: 0.4145841598510742, Accuracy: 0.84375\n","Epoch 8, Batch 134/161, Loss: 0.4071173369884491, Accuracy: 0.8125\n","Epoch 8, Batch 135/161, Loss: 0.30827656388282776, Accuracy: 0.90625\n","Epoch 8, Batch 136/161, Loss: 0.18730056285858154, Accuracy: 0.9375\n","Epoch 8, Batch 137/161, Loss: 0.2680701017379761, Accuracy: 0.84375\n","Epoch 8, Batch 138/161, Loss: 0.30313754081726074, Accuracy: 0.875\n","Epoch 8, Batch 139/161, Loss: 0.21749401092529297, Accuracy: 0.9375\n","Epoch 8, Batch 140/161, Loss: 0.2147204577922821, Accuracy: 0.90625\n","Epoch 8, Batch 141/161, Loss: 0.22773978114128113, Accuracy: 0.90625\n","Epoch 8, Batch 142/161, Loss: 0.2694634199142456, Accuracy: 0.90625\n","Epoch 8, Batch 143/161, Loss: 0.1691860556602478, Accuracy: 0.96875\n","Epoch 8, Batch 144/161, Loss: 0.40001100301742554, Accuracy: 0.8125\n","Epoch 8, Batch 145/161, Loss: 0.3226547837257385, Accuracy: 0.90625\n","Epoch 8, Batch 146/161, Loss: 0.2951013743877411, Accuracy: 0.84375\n","Epoch 8, Batch 147/161, Loss: 0.29520270228385925, Accuracy: 0.84375\n","Epoch 8, Batch 148/161, Loss: 0.32191112637519836, Accuracy: 0.875\n","Epoch 8, Batch 149/161, Loss: 0.34286898374557495, Accuracy: 0.84375\n","Epoch 8, Batch 150/161, Loss: 0.3712984323501587, Accuracy: 0.8125\n","Epoch 8, Batch 151/161, Loss: 0.2724948525428772, Accuracy: 0.84375\n","Epoch 8, Batch 152/161, Loss: 0.2302664965391159, Accuracy: 0.84375\n","Epoch 8, Batch 153/161, Loss: 0.3402675986289978, Accuracy: 0.84375\n","Epoch 8, Batch 154/161, Loss: 0.443972110748291, Accuracy: 0.84375\n","Epoch 8, Batch 155/161, Loss: 0.33604779839515686, Accuracy: 0.75\n","Epoch 8, Batch 156/161, Loss: 0.31823354959487915, Accuracy: 0.875\n","Epoch 8, Batch 157/161, Loss: 0.28919729590415955, Accuracy: 0.8125\n","Epoch 8, Batch 158/161, Loss: 0.3045085072517395, Accuracy: 0.78125\n","Epoch 8, Batch 159/161, Loss: 0.2110857367515564, Accuracy: 0.96875\n","Epoch 8, Batch 160/161, Loss: 0.1162046566605568, Accuracy: 0.96875\n","Epoch 8, Batch 161/161, Loss: 0.19846317172050476, Accuracy: 0.9375\n","Epoch 9, Batch 1/161, Loss: 0.13775502145290375, Accuracy: 0.96875\n","Epoch 9, Batch 2/161, Loss: 0.2141069769859314, Accuracy: 0.90625\n","Epoch 9, Batch 3/161, Loss: 0.16187648475170135, Accuracy: 0.90625\n","Epoch 9, Batch 4/161, Loss: 0.27918875217437744, Accuracy: 0.84375\n","Epoch 9, Batch 5/161, Loss: 0.1658526062965393, Accuracy: 0.9375\n","Epoch 9, Batch 6/161, Loss: 0.3214467763900757, Accuracy: 0.84375\n","Epoch 9, Batch 7/161, Loss: 0.33626776933670044, Accuracy: 0.8125\n","Epoch 9, Batch 8/161, Loss: 0.5336042046546936, Accuracy: 0.78125\n","Epoch 9, Batch 9/161, Loss: 0.45978793501853943, Accuracy: 0.78125\n","Epoch 9, Batch 10/161, Loss: 0.4832897186279297, Accuracy: 0.78125\n","Epoch 9, Batch 11/161, Loss: 0.43720901012420654, Accuracy: 0.78125\n","Epoch 9, Batch 12/161, Loss: 0.30414021015167236, Accuracy: 0.90625\n","Epoch 9, Batch 13/161, Loss: 0.35397833585739136, Accuracy: 0.875\n","Epoch 9, Batch 14/161, Loss: 0.3613724410533905, Accuracy: 0.875\n","Epoch 9, Batch 15/161, Loss: 0.36339545249938965, Accuracy: 0.78125\n","Epoch 9, Batch 16/161, Loss: 0.48937398195266724, Accuracy: 0.6875\n","Epoch 9, Batch 17/161, Loss: 0.41941195726394653, Accuracy: 0.78125\n","Epoch 9, Batch 18/161, Loss: 0.38142597675323486, Accuracy: 0.8125\n","Epoch 9, Batch 19/161, Loss: 0.2793160676956177, Accuracy: 0.84375\n","Epoch 9, Batch 20/161, Loss: 0.4158328175544739, Accuracy: 0.8125\n","Epoch 9, Batch 21/161, Loss: 0.41625478863716125, Accuracy: 0.71875\n","Epoch 9, Batch 22/161, Loss: 0.37938380241394043, Accuracy: 0.8125\n","Epoch 9, Batch 23/161, Loss: 0.2503476142883301, Accuracy: 0.90625\n","Epoch 9, Batch 24/161, Loss: 0.1738908290863037, Accuracy: 0.96875\n","Epoch 9, Batch 25/161, Loss: 0.33314794301986694, Accuracy: 0.8125\n","Epoch 9, Batch 26/161, Loss: 0.3262441158294678, Accuracy: 0.875\n","Epoch 9, Batch 27/161, Loss: 0.27880194783210754, Accuracy: 0.9375\n","Epoch 9, Batch 28/161, Loss: 0.3419821262359619, Accuracy: 0.875\n","Epoch 9, Batch 29/161, Loss: 0.23587240278720856, Accuracy: 0.90625\n","Epoch 9, Batch 30/161, Loss: 0.3996469974517822, Accuracy: 0.71875\n","Epoch 9, Batch 31/161, Loss: 0.30310145020484924, Accuracy: 0.90625\n","Epoch 9, Batch 32/161, Loss: 0.3777342736721039, Accuracy: 0.875\n","Epoch 9, Batch 33/161, Loss: 0.3896491527557373, Accuracy: 0.8125\n","Epoch 9, Batch 34/161, Loss: 0.26819583773612976, Accuracy: 0.875\n","Epoch 9, Batch 35/161, Loss: 0.33003634214401245, Accuracy: 0.90625\n","Epoch 9, Batch 36/161, Loss: 0.34192195534706116, Accuracy: 0.75\n","Epoch 9, Batch 37/161, Loss: 0.35113269090652466, Accuracy: 0.84375\n","Epoch 9, Batch 38/161, Loss: 0.46003079414367676, Accuracy: 0.78125\n","Epoch 9, Batch 39/161, Loss: 0.3034055233001709, Accuracy: 0.8125\n","Epoch 9, Batch 40/161, Loss: 0.27773526310920715, Accuracy: 0.90625\n","Epoch 9, Batch 41/161, Loss: 0.4289275109767914, Accuracy: 0.78125\n","Epoch 9, Batch 42/161, Loss: 0.2911500036716461, Accuracy: 0.8125\n","Epoch 9, Batch 43/161, Loss: 0.27931663393974304, Accuracy: 0.84375\n","Epoch 9, Batch 44/161, Loss: 0.2514112591743469, Accuracy: 0.9375\n","Epoch 9, Batch 45/161, Loss: 0.37512487173080444, Accuracy: 0.8125\n","Epoch 9, Batch 46/161, Loss: 0.53468918800354, Accuracy: 0.78125\n","Epoch 9, Batch 47/161, Loss: 0.42379122972488403, Accuracy: 0.78125\n","Epoch 9, Batch 48/161, Loss: 0.31670135259628296, Accuracy: 0.84375\n","Epoch 9, Batch 49/161, Loss: 0.3220871686935425, Accuracy: 0.84375\n","Epoch 9, Batch 50/161, Loss: 0.4313972294330597, Accuracy: 0.8125\n","Epoch 9, Batch 51/161, Loss: 0.3465839624404907, Accuracy: 0.8125\n","Epoch 9, Batch 52/161, Loss: 0.2815000116825104, Accuracy: 0.84375\n","Epoch 9, Batch 53/161, Loss: 0.3685516119003296, Accuracy: 0.78125\n","Epoch 9, Batch 54/161, Loss: 0.24314208328723907, Accuracy: 0.96875\n","Epoch 9, Batch 55/161, Loss: 0.3044436573982239, Accuracy: 0.90625\n","Epoch 9, Batch 56/161, Loss: 0.322964608669281, Accuracy: 0.8125\n","Epoch 9, Batch 57/161, Loss: 0.3170028030872345, Accuracy: 0.875\n","Epoch 9, Batch 58/161, Loss: 0.4086383581161499, Accuracy: 0.78125\n","Epoch 9, Batch 59/161, Loss: 0.16541042923927307, Accuracy: 0.9375\n","Epoch 9, Batch 60/161, Loss: 0.27356213331222534, Accuracy: 0.90625\n","Epoch 9, Batch 61/161, Loss: 0.3803430199623108, Accuracy: 0.84375\n","Epoch 9, Batch 62/161, Loss: 0.3262214958667755, Accuracy: 0.875\n","Epoch 9, Batch 63/161, Loss: 0.4378165900707245, Accuracy: 0.8125\n","Epoch 9, Batch 64/161, Loss: 0.3207092583179474, Accuracy: 0.875\n","Epoch 9, Batch 65/161, Loss: 0.3055267035961151, Accuracy: 0.8125\n","Epoch 9, Batch 66/161, Loss: 0.2312016487121582, Accuracy: 0.96875\n","Epoch 9, Batch 67/161, Loss: 0.2541780471801758, Accuracy: 0.9375\n","Epoch 9, Batch 68/161, Loss: 0.23815858364105225, Accuracy: 0.90625\n","Epoch 9, Batch 69/161, Loss: 0.18855801224708557, Accuracy: 0.90625\n","Epoch 9, Batch 70/161, Loss: 0.2410557121038437, Accuracy: 0.875\n","Epoch 9, Batch 71/161, Loss: 0.2692495286464691, Accuracy: 0.90625\n","Epoch 9, Batch 72/161, Loss: 0.29695838689804077, Accuracy: 0.8125\n","Epoch 9, Batch 73/161, Loss: 0.3337640166282654, Accuracy: 0.875\n","Epoch 9, Batch 74/161, Loss: 0.33328044414520264, Accuracy: 0.8125\n","Epoch 9, Batch 75/161, Loss: 0.2512013018131256, Accuracy: 0.875\n","Epoch 9, Batch 76/161, Loss: 0.2573085427284241, Accuracy: 0.90625\n","Epoch 9, Batch 77/161, Loss: 0.23958168923854828, Accuracy: 0.875\n","Epoch 9, Batch 78/161, Loss: 0.3327922523021698, Accuracy: 0.78125\n","Epoch 9, Batch 79/161, Loss: 0.2205781489610672, Accuracy: 0.9375\n","Epoch 9, Batch 80/161, Loss: 0.3423978388309479, Accuracy: 0.84375\n","Epoch 9, Batch 81/161, Loss: 0.2726329267024994, Accuracy: 0.875\n","Epoch 9, Batch 82/161, Loss: 0.282626748085022, Accuracy: 0.875\n","Epoch 9, Batch 83/161, Loss: 0.2876545190811157, Accuracy: 0.875\n","Epoch 9, Batch 84/161, Loss: 0.20298682153224945, Accuracy: 0.9375\n","Epoch 9, Batch 85/161, Loss: 0.3096807301044464, Accuracy: 0.84375\n","Epoch 9, Batch 86/161, Loss: 0.5202487111091614, Accuracy: 0.625\n","Epoch 9, Batch 87/161, Loss: 0.19763794541358948, Accuracy: 0.9375\n","Epoch 9, Batch 88/161, Loss: 0.4078003168106079, Accuracy: 0.78125\n","Epoch 9, Batch 89/161, Loss: 0.2884005904197693, Accuracy: 0.875\n","Epoch 9, Batch 90/161, Loss: 0.16023604571819305, Accuracy: 0.9375\n","Epoch 9, Batch 91/161, Loss: 0.2654770016670227, Accuracy: 0.875\n","Epoch 9, Batch 92/161, Loss: 0.3056910037994385, Accuracy: 0.90625\n","Epoch 9, Batch 93/161, Loss: 0.32910454273223877, Accuracy: 0.875\n","Epoch 9, Batch 94/161, Loss: 0.2133827954530716, Accuracy: 0.9375\n","Epoch 9, Batch 95/161, Loss: 0.3012635111808777, Accuracy: 0.84375\n","Epoch 9, Batch 96/161, Loss: 0.3734864592552185, Accuracy: 0.875\n","Epoch 9, Batch 97/161, Loss: 0.4836163818836212, Accuracy: 0.75\n","Epoch 9, Batch 98/161, Loss: 0.26540762186050415, Accuracy: 0.8125\n","Epoch 9, Batch 99/161, Loss: 0.38715898990631104, Accuracy: 0.84375\n","Epoch 9, Batch 100/161, Loss: 0.2610589861869812, Accuracy: 0.875\n","Epoch 9, Batch 101/161, Loss: 0.2738765478134155, Accuracy: 0.875\n","Epoch 9, Batch 102/161, Loss: 0.4471975266933441, Accuracy: 0.71875\n","Epoch 9, Batch 103/161, Loss: 0.24173876643180847, Accuracy: 0.96875\n","Epoch 9, Batch 104/161, Loss: 0.34420472383499146, Accuracy: 0.78125\n","Epoch 9, Batch 105/161, Loss: 0.23081301152706146, Accuracy: 0.875\n","Epoch 9, Batch 106/161, Loss: 0.367352157831192, Accuracy: 0.8125\n","Epoch 9, Batch 107/161, Loss: 0.4270905554294586, Accuracy: 0.71875\n","Epoch 9, Batch 108/161, Loss: 0.29528364539146423, Accuracy: 0.84375\n","Epoch 9, Batch 109/161, Loss: 0.2261759638786316, Accuracy: 0.9375\n","Epoch 9, Batch 110/161, Loss: 0.38885608315467834, Accuracy: 0.8125\n","Epoch 9, Batch 111/161, Loss: 0.18762299418449402, Accuracy: 0.9375\n","Epoch 9, Batch 112/161, Loss: 0.28003743290901184, Accuracy: 0.90625\n","Epoch 9, Batch 113/161, Loss: 0.19221940636634827, Accuracy: 0.90625\n","Epoch 9, Batch 114/161, Loss: 0.2650582492351532, Accuracy: 0.90625\n","Epoch 9, Batch 115/161, Loss: 0.4308418333530426, Accuracy: 0.75\n","Epoch 9, Batch 116/161, Loss: 0.3362343907356262, Accuracy: 0.84375\n","Epoch 9, Batch 117/161, Loss: 0.20157819986343384, Accuracy: 0.9375\n","Epoch 9, Batch 118/161, Loss: 0.21434292197227478, Accuracy: 0.90625\n","Epoch 9, Batch 119/161, Loss: 0.15046945214271545, Accuracy: 0.9375\n","Epoch 9, Batch 120/161, Loss: 0.26507866382598877, Accuracy: 0.84375\n","Epoch 9, Batch 121/161, Loss: 0.3634738624095917, Accuracy: 0.9375\n","Epoch 9, Batch 122/161, Loss: 0.38126683235168457, Accuracy: 0.84375\n","Epoch 9, Batch 123/161, Loss: 0.28345412015914917, Accuracy: 0.875\n","Epoch 9, Batch 124/161, Loss: 0.31319695711135864, Accuracy: 0.8125\n","Epoch 9, Batch 125/161, Loss: 0.3663554787635803, Accuracy: 0.84375\n","Epoch 9, Batch 126/161, Loss: 0.37510332465171814, Accuracy: 0.8125\n","Epoch 9, Batch 127/161, Loss: 0.2602611184120178, Accuracy: 0.875\n","Epoch 9, Batch 128/161, Loss: 0.36426952481269836, Accuracy: 0.84375\n","Epoch 9, Batch 129/161, Loss: 0.34633275866508484, Accuracy: 0.84375\n","Epoch 9, Batch 130/161, Loss: 0.3863583207130432, Accuracy: 0.75\n","Epoch 9, Batch 131/161, Loss: 0.19666704535484314, Accuracy: 0.9375\n","Epoch 9, Batch 132/161, Loss: 0.41141730546951294, Accuracy: 0.8125\n","Epoch 9, Batch 133/161, Loss: 0.4137313961982727, Accuracy: 0.78125\n","Epoch 9, Batch 134/161, Loss: 0.35043516755104065, Accuracy: 0.8125\n","Epoch 9, Batch 135/161, Loss: 0.2991587519645691, Accuracy: 0.90625\n","Epoch 9, Batch 136/161, Loss: 0.17188628017902374, Accuracy: 0.96875\n","Epoch 9, Batch 137/161, Loss: 0.26853933930397034, Accuracy: 0.84375\n","Epoch 9, Batch 138/161, Loss: 0.2921402156352997, Accuracy: 0.875\n","Epoch 9, Batch 139/161, Loss: 0.2187485247850418, Accuracy: 0.9375\n","Epoch 9, Batch 140/161, Loss: 0.1844366043806076, Accuracy: 0.96875\n","Epoch 9, Batch 141/161, Loss: 0.22197487950325012, Accuracy: 0.90625\n","Epoch 9, Batch 142/161, Loss: 0.17077459394931793, Accuracy: 0.9375\n","Epoch 9, Batch 143/161, Loss: 0.16300129890441895, Accuracy: 0.9375\n","Epoch 9, Batch 144/161, Loss: 0.3006676435470581, Accuracy: 0.84375\n","Epoch 9, Batch 145/161, Loss: 0.30290311574935913, Accuracy: 0.90625\n","Epoch 9, Batch 146/161, Loss: 0.29709601402282715, Accuracy: 0.78125\n","Epoch 9, Batch 147/161, Loss: 0.2677820026874542, Accuracy: 0.875\n","Epoch 9, Batch 148/161, Loss: 0.27606892585754395, Accuracy: 0.875\n","Epoch 9, Batch 149/161, Loss: 0.32968562841415405, Accuracy: 0.84375\n","Epoch 9, Batch 150/161, Loss: 0.3337560296058655, Accuracy: 0.8125\n","Epoch 9, Batch 151/161, Loss: 0.25284454226493835, Accuracy: 0.84375\n","Epoch 9, Batch 152/161, Loss: 0.23228111863136292, Accuracy: 0.84375\n","Epoch 9, Batch 153/161, Loss: 0.26776212453842163, Accuracy: 0.875\n","Epoch 9, Batch 154/161, Loss: 0.3967862129211426, Accuracy: 0.875\n","Epoch 9, Batch 155/161, Loss: 0.33817383646965027, Accuracy: 0.75\n","Epoch 9, Batch 156/161, Loss: 0.2814190685749054, Accuracy: 0.875\n","Epoch 9, Batch 157/161, Loss: 0.2564294934272766, Accuracy: 0.8125\n","Epoch 9, Batch 158/161, Loss: 0.3810146450996399, Accuracy: 0.8125\n","Epoch 9, Batch 159/161, Loss: 0.22750234603881836, Accuracy: 0.9375\n","Epoch 9, Batch 160/161, Loss: 0.14839717745780945, Accuracy: 0.96875\n","Epoch 9, Batch 161/161, Loss: 0.1842576116323471, Accuracy: 0.9375\n","Epoch 10, Batch 1/161, Loss: 0.17088326811790466, Accuracy: 0.9375\n","Epoch 10, Batch 2/161, Loss: 0.22380027174949646, Accuracy: 0.9375\n","Epoch 10, Batch 3/161, Loss: 0.1346820890903473, Accuracy: 0.96875\n","Epoch 10, Batch 4/161, Loss: 0.2630927562713623, Accuracy: 0.84375\n","Epoch 10, Batch 5/161, Loss: 0.16221007704734802, Accuracy: 0.9375\n","Epoch 10, Batch 6/161, Loss: 0.2890786826610565, Accuracy: 0.84375\n","Epoch 10, Batch 7/161, Loss: 0.23324671387672424, Accuracy: 0.875\n","Epoch 10, Batch 8/161, Loss: 0.5084841251373291, Accuracy: 0.84375\n","Epoch 10, Batch 9/161, Loss: 0.8352892398834229, Accuracy: 0.78125\n","Epoch 10, Batch 10/161, Loss: 0.48214054107666016, Accuracy: 0.75\n","Epoch 10, Batch 11/161, Loss: 0.3742544651031494, Accuracy: 0.84375\n","Epoch 10, Batch 12/161, Loss: 0.2712492346763611, Accuracy: 0.90625\n","Epoch 10, Batch 13/161, Loss: 0.329345166683197, Accuracy: 0.84375\n","Epoch 10, Batch 14/161, Loss: 0.35288944840431213, Accuracy: 0.8125\n","Epoch 10, Batch 15/161, Loss: 0.3465646505355835, Accuracy: 0.8125\n","Epoch 10, Batch 16/161, Loss: 0.4377036690711975, Accuracy: 0.75\n","Epoch 10, Batch 17/161, Loss: 0.41509732604026794, Accuracy: 0.75\n","Epoch 10, Batch 18/161, Loss: 0.3575900197029114, Accuracy: 0.875\n","Epoch 10, Batch 19/161, Loss: 0.27412253618240356, Accuracy: 0.84375\n","Epoch 10, Batch 20/161, Loss: 0.35962337255477905, Accuracy: 0.84375\n","Epoch 10, Batch 21/161, Loss: 0.46897077560424805, Accuracy: 0.75\n","Epoch 10, Batch 22/161, Loss: 0.3117218017578125, Accuracy: 0.90625\n","Epoch 10, Batch 23/161, Loss: 0.2166331559419632, Accuracy: 0.90625\n","Epoch 10, Batch 24/161, Loss: 0.16308262944221497, Accuracy: 0.9375\n","Epoch 10, Batch 25/161, Loss: 0.3100488781929016, Accuracy: 0.8125\n","Epoch 10, Batch 26/161, Loss: 0.3354688286781311, Accuracy: 0.875\n","Epoch 10, Batch 27/161, Loss: 0.25908514857292175, Accuracy: 0.9375\n","Epoch 10, Batch 28/161, Loss: 0.31564924120903015, Accuracy: 0.90625\n","Epoch 10, Batch 29/161, Loss: 0.22590085864067078, Accuracy: 0.90625\n","Epoch 10, Batch 30/161, Loss: 0.3778308928012848, Accuracy: 0.78125\n","Epoch 10, Batch 31/161, Loss: 0.30392852425575256, Accuracy: 0.84375\n","Epoch 10, Batch 32/161, Loss: 0.20876702666282654, Accuracy: 0.9375\n","Epoch 10, Batch 33/161, Loss: 0.3493298292160034, Accuracy: 0.84375\n","Epoch 10, Batch 34/161, Loss: 0.23091262578964233, Accuracy: 0.875\n","Epoch 10, Batch 35/161, Loss: 0.3388291001319885, Accuracy: 0.875\n","Epoch 10, Batch 36/161, Loss: 0.2811303436756134, Accuracy: 0.84375\n","Epoch 10, Batch 37/161, Loss: 0.3426250219345093, Accuracy: 0.8125\n","Epoch 10, Batch 38/161, Loss: 0.45345255732536316, Accuracy: 0.75\n","Epoch 10, Batch 39/161, Loss: 0.300091028213501, Accuracy: 0.84375\n","Epoch 10, Batch 40/161, Loss: 0.23415187001228333, Accuracy: 0.9375\n","Epoch 10, Batch 41/161, Loss: 0.42619946599006653, Accuracy: 0.78125\n","Epoch 10, Batch 42/161, Loss: 0.28983932733535767, Accuracy: 0.84375\n","Epoch 10, Batch 43/161, Loss: 0.2873804569244385, Accuracy: 0.8125\n","Epoch 10, Batch 44/161, Loss: 0.2977006733417511, Accuracy: 0.90625\n","Epoch 10, Batch 45/161, Loss: 0.3988584876060486, Accuracy: 0.78125\n","Epoch 10, Batch 46/161, Loss: 0.31818026304244995, Accuracy: 0.84375\n","Epoch 10, Batch 47/161, Loss: 0.35346198081970215, Accuracy: 0.8125\n","Epoch 10, Batch 48/161, Loss: 0.46735048294067383, Accuracy: 0.84375\n","Epoch 10, Batch 49/161, Loss: 0.46716371178627014, Accuracy: 0.8125\n","Epoch 10, Batch 50/161, Loss: 0.3622472286224365, Accuracy: 0.875\n","Epoch 10, Batch 51/161, Loss: 0.30711862444877625, Accuracy: 0.84375\n","Epoch 10, Batch 52/161, Loss: 0.26968222856521606, Accuracy: 0.90625\n","Epoch 10, Batch 53/161, Loss: 0.3769429326057434, Accuracy: 0.78125\n","Epoch 10, Batch 54/161, Loss: 0.22681385278701782, Accuracy: 0.96875\n","Epoch 10, Batch 55/161, Loss: 0.3648473918437958, Accuracy: 0.8125\n","Epoch 10, Batch 56/161, Loss: 0.3749580383300781, Accuracy: 0.78125\n","Epoch 10, Batch 57/161, Loss: 0.313748836517334, Accuracy: 0.875\n","Epoch 10, Batch 58/161, Loss: 0.32042446732521057, Accuracy: 0.84375\n","Epoch 10, Batch 59/161, Loss: 0.1411471664905548, Accuracy: 0.96875\n","Epoch 10, Batch 60/161, Loss: 0.2887423634529114, Accuracy: 0.84375\n","Epoch 10, Batch 61/161, Loss: 0.361674427986145, Accuracy: 0.8125\n","Epoch 10, Batch 62/161, Loss: 0.2920832335948944, Accuracy: 0.875\n","Epoch 10, Batch 63/161, Loss: 0.4000009298324585, Accuracy: 0.8125\n","Epoch 10, Batch 64/161, Loss: 0.2888333201408386, Accuracy: 0.84375\n","Epoch 10, Batch 65/161, Loss: 0.25823426246643066, Accuracy: 0.875\n","Epoch 10, Batch 66/161, Loss: 0.1985674351453781, Accuracy: 0.96875\n","Epoch 10, Batch 67/161, Loss: 0.2708333432674408, Accuracy: 0.90625\n","Epoch 10, Batch 68/161, Loss: 0.21828299760818481, Accuracy: 0.9375\n","Epoch 10, Batch 69/161, Loss: 0.17241328954696655, Accuracy: 0.96875\n","Epoch 10, Batch 70/161, Loss: 0.201706200838089, Accuracy: 0.9375\n","Epoch 10, Batch 71/161, Loss: 0.23522651195526123, Accuracy: 0.875\n","Epoch 10, Batch 72/161, Loss: 0.21475063264369965, Accuracy: 0.875\n","Epoch 10, Batch 73/161, Loss: 0.22899025678634644, Accuracy: 0.875\n","Epoch 10, Batch 74/161, Loss: 0.3386513590812683, Accuracy: 0.8125\n","Epoch 10, Batch 75/161, Loss: 0.2515791952610016, Accuracy: 0.875\n","Epoch 10, Batch 76/161, Loss: 0.2143908143043518, Accuracy: 0.9375\n","Epoch 10, Batch 77/161, Loss: 0.19336307048797607, Accuracy: 0.9375\n","Epoch 10, Batch 78/161, Loss: 0.31608301401138306, Accuracy: 0.75\n","Epoch 10, Batch 79/161, Loss: 0.2120247483253479, Accuracy: 0.9375\n","Epoch 10, Batch 80/161, Loss: 0.3165837526321411, Accuracy: 0.84375\n","Epoch 10, Batch 81/161, Loss: 0.30386796593666077, Accuracy: 0.875\n","Epoch 10, Batch 82/161, Loss: 0.19778579473495483, Accuracy: 0.875\n","Epoch 10, Batch 83/161, Loss: 0.27913984656333923, Accuracy: 0.84375\n","Epoch 10, Batch 84/161, Loss: 0.18908652663230896, Accuracy: 0.9375\n","Epoch 10, Batch 85/161, Loss: 0.3067074120044708, Accuracy: 0.84375\n","Epoch 10, Batch 86/161, Loss: 0.49525123834609985, Accuracy: 0.6875\n","Epoch 10, Batch 87/161, Loss: 0.2535347640514374, Accuracy: 0.90625\n","Epoch 10, Batch 88/161, Loss: 0.3429776132106781, Accuracy: 0.8125\n","Epoch 10, Batch 89/161, Loss: 0.2838873267173767, Accuracy: 0.875\n","Epoch 10, Batch 90/161, Loss: 0.13834887742996216, Accuracy: 0.9375\n","Epoch 10, Batch 91/161, Loss: 0.2189585566520691, Accuracy: 0.90625\n","Epoch 10, Batch 92/161, Loss: 0.29356175661087036, Accuracy: 0.90625\n","Epoch 10, Batch 93/161, Loss: 0.3116390109062195, Accuracy: 0.875\n","Epoch 10, Batch 94/161, Loss: 0.19661368429660797, Accuracy: 0.9375\n","Epoch 10, Batch 95/161, Loss: 0.2535095810890198, Accuracy: 0.875\n","Epoch 10, Batch 96/161, Loss: 0.3587358295917511, Accuracy: 0.875\n","Epoch 10, Batch 97/161, Loss: 0.4979603886604309, Accuracy: 0.75\n","Epoch 10, Batch 98/161, Loss: 0.1794186532497406, Accuracy: 0.96875\n","Epoch 10, Batch 99/161, Loss: 0.2910996675491333, Accuracy: 0.84375\n","Epoch 10, Batch 100/161, Loss: 0.17060604691505432, Accuracy: 0.96875\n","Epoch 10, Batch 101/161, Loss: 0.2367725670337677, Accuracy: 0.875\n","Epoch 10, Batch 102/161, Loss: 0.4567911922931671, Accuracy: 0.71875\n","Epoch 10, Batch 103/161, Loss: 0.2011091411113739, Accuracy: 0.96875\n","Epoch 10, Batch 104/161, Loss: 0.33522897958755493, Accuracy: 0.8125\n","Epoch 10, Batch 105/161, Loss: 0.22347596287727356, Accuracy: 0.875\n","Epoch 10, Batch 106/161, Loss: 0.31626957654953003, Accuracy: 0.84375\n","Epoch 10, Batch 107/161, Loss: 0.4328260123729706, Accuracy: 0.75\n","Epoch 10, Batch 108/161, Loss: 0.3158121407032013, Accuracy: 0.84375\n","Epoch 10, Batch 109/161, Loss: 0.19226300716400146, Accuracy: 0.96875\n","Epoch 10, Batch 110/161, Loss: 0.372886061668396, Accuracy: 0.8125\n","Epoch 10, Batch 111/161, Loss: 0.17768625915050507, Accuracy: 0.9375\n","Epoch 10, Batch 112/161, Loss: 0.2456323206424713, Accuracy: 0.9375\n","Epoch 10, Batch 113/161, Loss: 0.20233675837516785, Accuracy: 0.9375\n","Epoch 10, Batch 114/161, Loss: 0.27514463663101196, Accuracy: 0.90625\n","Epoch 10, Batch 115/161, Loss: 0.3962683379650116, Accuracy: 0.84375\n","Epoch 10, Batch 116/161, Loss: 0.3042438328266144, Accuracy: 0.875\n","Epoch 10, Batch 117/161, Loss: 0.20299848914146423, Accuracy: 0.9375\n","Epoch 10, Batch 118/161, Loss: 0.20467789471149445, Accuracy: 0.90625\n","Epoch 10, Batch 119/161, Loss: 0.1352396011352539, Accuracy: 0.96875\n","Epoch 10, Batch 120/161, Loss: 0.23377001285552979, Accuracy: 0.875\n","Epoch 10, Batch 121/161, Loss: 0.33054783940315247, Accuracy: 0.90625\n","Epoch 10, Batch 122/161, Loss: 0.3619241416454315, Accuracy: 0.8125\n","Epoch 10, Batch 123/161, Loss: 0.2155608981847763, Accuracy: 0.90625\n","Epoch 10, Batch 124/161, Loss: 0.3327729105949402, Accuracy: 0.84375\n","Epoch 10, Batch 125/161, Loss: 0.3409004807472229, Accuracy: 0.8125\n","Epoch 10, Batch 126/161, Loss: 0.36490198969841003, Accuracy: 0.84375\n","Epoch 10, Batch 127/161, Loss: 0.2479695826768875, Accuracy: 0.875\n","Epoch 10, Batch 128/161, Loss: 0.3383999764919281, Accuracy: 0.84375\n","Epoch 10, Batch 129/161, Loss: 0.29192054271698, Accuracy: 0.875\n","Epoch 10, Batch 130/161, Loss: 0.36545050144195557, Accuracy: 0.78125\n","Epoch 10, Batch 131/161, Loss: 0.19196747243404388, Accuracy: 0.90625\n","Epoch 10, Batch 132/161, Loss: 0.39070388674736023, Accuracy: 0.8125\n","Epoch 10, Batch 133/161, Loss: 0.39490607380867004, Accuracy: 0.8125\n","Epoch 10, Batch 134/161, Loss: 0.3318238854408264, Accuracy: 0.84375\n","Epoch 10, Batch 135/161, Loss: 0.27524688839912415, Accuracy: 0.90625\n","Epoch 10, Batch 136/161, Loss: 0.14017707109451294, Accuracy: 1.0\n","Epoch 10, Batch 137/161, Loss: 0.2049725353717804, Accuracy: 0.9375\n","Epoch 10, Batch 138/161, Loss: 0.2853996753692627, Accuracy: 0.875\n","Epoch 10, Batch 139/161, Loss: 0.19067859649658203, Accuracy: 0.9375\n","Epoch 10, Batch 140/161, Loss: 0.17819684743881226, Accuracy: 0.96875\n","Epoch 10, Batch 141/161, Loss: 0.20731444656848907, Accuracy: 0.9375\n","Epoch 10, Batch 142/161, Loss: 0.1292867213487625, Accuracy: 1.0\n","Epoch 10, Batch 143/161, Loss: 0.1419130116701126, Accuracy: 0.96875\n","Epoch 10, Batch 144/161, Loss: 0.19018925726413727, Accuracy: 0.9375\n","Epoch 10, Batch 145/161, Loss: 0.22710278630256653, Accuracy: 0.90625\n","Epoch 10, Batch 146/161, Loss: 0.2786310017108917, Accuracy: 0.84375\n","Epoch 10, Batch 147/161, Loss: 0.3332288861274719, Accuracy: 0.875\n","Epoch 10, Batch 148/161, Loss: 0.2722565233707428, Accuracy: 0.875\n","Epoch 10, Batch 149/161, Loss: 0.3593018054962158, Accuracy: 0.875\n","Epoch 10, Batch 150/161, Loss: 0.34110456705093384, Accuracy: 0.84375\n","Epoch 10, Batch 151/161, Loss: 0.27309197187423706, Accuracy: 0.875\n","Epoch 10, Batch 152/161, Loss: 0.2210800051689148, Accuracy: 0.8125\n","Epoch 10, Batch 153/161, Loss: 0.28270015120506287, Accuracy: 0.875\n","Epoch 10, Batch 154/161, Loss: 0.3796602785587311, Accuracy: 0.875\n","Epoch 10, Batch 155/161, Loss: 0.31238940358161926, Accuracy: 0.8125\n","Epoch 10, Batch 156/161, Loss: 0.2575525641441345, Accuracy: 0.90625\n","Epoch 10, Batch 157/161, Loss: 0.267073392868042, Accuracy: 0.8125\n","Epoch 10, Batch 158/161, Loss: 0.3022001385688782, Accuracy: 0.78125\n","Epoch 10, Batch 159/161, Loss: 0.17965060472488403, Accuracy: 0.9375\n","Epoch 10, Batch 160/161, Loss: 0.1516728550195694, Accuracy: 0.96875\n","Epoch 10, Batch 161/161, Loss: 0.2559807300567627, Accuracy: 0.90625\n"]}],"source":["# Train the discriminator\n","batch_size = 32  # Adjust as needed\n","num_epochs = 10  # Adjust as needed\n","num_batches = len(padded_sequences) // batch_size\n","\n","for epoch in range(num_epochs):\n","    for batch in range(num_batches):\n","        # Prepare a batch of real data and labels\n","        batch_data = padded_sequences[batch * batch_size : (batch + 1) * batch_size]\n","        batch_labels = labels[batch * batch_size : (batch + 1) * batch_size]\n","        \n","        # Train the discriminator on the batch of real data\n","        discriminator_loss = discriminator.train_on_batch(batch_data, batch_labels)\n","        \n","        # Monitor and log the losses and progress as needed\n","        print(f\"Epoch {epoch + 1}, Batch {batch + 1}/{num_batches}, Loss: {discriminator_loss[0]}, Accuracy: {discriminator_loss[1]}\")\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:34:08.376283Z","iopub.status.busy":"2024-05-18T14:34:08.375676Z","iopub.status.idle":"2024-05-18T14:34:08.393918Z","shell.execute_reply":"2024-05-18T14:34:08.393278Z","shell.execute_reply.started":"2024-05-18T14:13:50.72614Z"},"papermill":{"duration":0.20655,"end_time":"2024-05-18T14:34:08.394027","exception":false,"start_time":"2024-05-18T14:34:08.187477","status":"completed"},"tags":[]},"outputs":[],"source":["# Save the trained discriminator weights\n","discriminator.save_weights('discriminator_weights.h5')"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:34:08.769347Z","iopub.status.busy":"2024-05-18T14:34:08.76814Z","iopub.status.idle":"2024-05-18T14:34:09.093942Z","shell.execute_reply":"2024-05-18T14:34:09.093412Z","shell.execute_reply.started":"2024-05-18T14:13:53.277981Z"},"papermill":{"duration":0.516344,"end_time":"2024-05-18T14:34:09.094055","exception":false,"start_time":"2024-05-18T14:34:08.577711","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Email 1: Congratulations! You've won a million dollars!\n","Predicted Class: Ham\n","Predicted Score: 0.18171045184135437\n","\n","Email 2: Hi there, I hope you're doing well.\n","Predicted Class: Spam\n","Predicted Score: 0.5032325983047485\n","\n","Email 3: Get a discount on our new products today!\n","Predicted Class: Ham\n","Predicted Score: 0.4429335296154022\n","\n","Email 4: Important: Your account security information\n","Predicted Class: Spam\n","Predicted Score: 0.5109655261039734\n","\n","Email 5: Free trial offer for our premium service\n","Predicted Class: Ham\n","Predicted Score: 0.299944132566452\n","\n"]}],"source":["# Sample email texts\n","sample_email_texts = [\n","    \"Congratulations! You've won a million dollars!\",\n","    \"Hi there, I hope you're doing well.\",\n","    \"Get a discount on our new products today!\",\n","    \"Important: Your account security information\",\n","    \"Free trial offer for our premium service\"\n","]\n","\n","# Tokenize and pad the sample email texts\n","max_sequence_length = 100  # Assuming the same max_sequence_length used during training\n","sequences = tokenizer.texts_to_sequences(sample_email_texts)\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n","\n","# Use the trained discriminator to classify the emails\n","predicted_labels = discriminator.predict(padded_sequences)\n","\n","# Convert predicted labels to 'Spam' or 'Ham'\n","predicted_classes = [\"Spam\" if label >= 0.5 else \"Ham\" for label in predicted_labels]\n","\n","# Print the results\n","for i, email in enumerate(sample_email_texts):\n","    print(f\"Email {i + 1}: {email}\")\n","    print(f\"Predicted Class: {predicted_classes[i]}\")\n","    print(f\"Predicted Score: {predicted_labels[i][0]}\")\n","    print()\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-05-18T14:34:09.465403Z","iopub.status.busy":"2024-05-18T14:34:09.464513Z","iopub.status.idle":"2024-05-18T14:34:09.505872Z","shell.execute_reply":"2024-05-18T14:34:09.505201Z","shell.execute_reply.started":"2024-05-18T14:16:28.915509Z"},"papermill":{"duration":0.231429,"end_time":"2024-05-18T14:34:09.505982","exception":false,"start_time":"2024-05-18T14:34:09.274553","status":"completed"},"tags":[]},"outputs":[{"name":"stdout","output_type":"stream","text":["Email 1: Congratulations! You've won a million dollars!\n","Predicted Class: Ham\n","Predicted Score: 0.18171045184135437\n","\n","Email 2: Hi there, I hope you're doing well.\n","Predicted Class: Spam\n","Predicted Score: 0.5032325983047485\n","\n","Email 3: Get a discount on our new products today!\n","Predicted Class: Ham\n","Predicted Score: 0.4429335296154022\n","\n","Email 4: Important: Your account security information\n","Predicted Class: Spam\n","Predicted Score: 0.5109655261039734\n","\n","Email 5: Free trial offer for our premium service\n","Predicted Class: Ham\n","Predicted Score: 0.299944132566452\n","\n"]}],"source":["# Sample email texts\n","sample_email_texts = [\n","    \"Congratulations! You've won a million dollars!\",\n","    \"Hi there, I hope you're doing well.\",\n","    \"Get a discount on our new products today!\",\n","    \"Important: Your account security information\",\n","    \"Free trial offer for our premium service\"\n","]\n","\n","# Tokenize and pad the sample email texts\n","max_sequence_length = 100  # Assuming the same max_sequence_length used during training\n","sequences = tokenizer.texts_to_sequences(sample_email_texts)\n","padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n","\n","# Use the trained discriminator to classify the emails\n","predicted_labels = discriminator.predict(padded_sequences)\n","\n","# Convert predicted labels to 'Spam' or 'Ham'\n","predicted_classes = [\"Spam\" if label >= 0.5 else \"Ham\" for label in predicted_labels]\n","\n","# Print the results\n","for i, email in enumerate(sample_email_texts):\n","    print(f\"Email {i + 1}: {email}\")\n","    print(f\"Predicted Class: {predicted_classes[i]}\")\n","    print(f\"Predicted Score: {predicted_labels[i][0]}\")\n","    print()\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":109196,"sourceId":260807,"sourceType":"datasetVersion"}],"dockerImageVersionId":30028,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"papermill":{"duration":235.306699,"end_time":"2024-05-18T14:34:09.8927","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-05-18T14:30:14.586001","version":"2.1.0"}},"nbformat":4,"nbformat_minor":4}